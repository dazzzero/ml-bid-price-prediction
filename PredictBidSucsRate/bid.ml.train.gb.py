# -*- coding: utf-8 -*-
"""
ì…ì°° ì„±ê³µë¥  ì˜ˆì¸¡ ì‹œìŠ¤í…œ - ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
Created on Mon Dec  2 10:14:33 2024

@author: user

ì´ íŒŒì¼ì˜ ëª©ì :
- ì¡°ë‹¬ì²­ ì…ì°° ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ìŠ¤í¬ë¦½íŠ¸
- 3ê°œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ í›ˆë ¨ (ì—…ì²´íˆ¬ì°°ë¥ , ì˜ˆê°€íˆ¬ì°°ë¥ , ì°¸ì—¬ì—…ì²´ìˆ˜ ì˜ˆì¸¡)
- XGBoost, LightGBM, GradientBoostingRegressor ì§€ì›
- í›ˆë ¨ëœ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ë„êµ¬ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
- í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ TF-IDF ë°©ì‹ìœ¼ë¡œ ë²¡í„°í™”í•˜ì—¬ ìˆ«ìë¡œ ë³€í™˜
"""

# ===== í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ import =====
import os  # íŒŒì¼ ê²½ë¡œ ì¡°ì‘ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import joblib  # ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import numpy as np  # ìˆ˜ì¹˜ ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (í–‰ë ¬, ë°°ì—´ ì—°ì‚°)
import random as rnd  # ëœë¤ ìˆ«ì ìƒì„±

from time import time  # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd  # ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì—‘ì…€ê³¼ ë¹„ìŠ·í•œ ê¸°ëŠ¥)

# ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ (í†µê³„ ì¶”ê°€ìš©)
try:
    import openpyxl
    from openpyxl import load_workbook
    OPENPYXL_AVAILABLE = True
except ImportError:
    OPENPYXL_AVAILABLE = False
    print("âš ï¸  openpyxlì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì—‘ì…€ í†µê³„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install openpyxl'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from kiwipiepy import Kiwi  # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° (ë‹¨ì–´ë¥¼ ìª¼ê°œëŠ” ë„êµ¬)

# í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬ë“¤
from sklearn.feature_extraction.text import TfidfVectorizer  # í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜
from scipy.sparse import csr_matrix  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ í–‰ë ¬ ì €ì¥ ë°©ì‹

# ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ë„êµ¬ë“¤
from sklearn.ensemble import GradientBoostingRegressor  # ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… íšŒê·€ ëª¨ë¸
from sklearn.preprocessing import StandardScaler  # ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ëŠ” ë„êµ¬ (0~1 ì‚¬ì´ë¡œ ë§ì¶¤)

# ê³ ì„±ëŠ¥ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    import xgboost as xgb  # XGBoost (Extreme Gradient Boosting)
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("âš ï¸  XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install xgboost'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

try:
    import lightgbm as lgb  # LightGBM (Light Gradient Boosting Machine)
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    print("âš ï¸  LightGBMì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install lightgbm'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# ë°ì´í„° ë¶„í•  ë„êµ¬
from sklearn.model_selection import train_test_split  # í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„í• 


class KiwiTokenizer():
    """
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ (predict.pyì™€ ë™ì¼)
    
    ì´ í´ë˜ìŠ¤ì˜ ì—­í• :
    1. í•œêµ­ì–´ ë¬¸ì¥ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìª¼ê°œê¸° (í˜•íƒœì†Œ ë¶„ì„)
    2. ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ ì¶”ì¶œí•˜ê¸° (ëª…ì‚¬, í˜•ìš©ì‚¬ ë“±)
    3. ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°í•˜ê¸° (ê´„í˜¸, íŠ¹ìˆ˜ë¬¸ì ë“±)
    
    ì˜ˆì‹œ: "ì„œìš¸ì‹œì²­ ê±´ë¬¼ ì‹ ì¶•ê³µì‚¬" â†’ ["ì„œìš¸ì‹œì²­", "ê±´ë¬¼", "ì‹ ì¶•", "ê³µì‚¬"]
    """
    
    def __init__(self, saved_filenm):
        """
        KiwiTokenizer ì´ˆê¸°í™” í•¨ìˆ˜
        
        Args:
            saved_filenm (str): ì €ì¥ëœ ì‚¬ì „ íŒŒì¼ëª… (ì´ì „ì— í•™ìŠµí•œ ë‹¨ì–´ì‚¬ì „ì„ ë¶ˆëŸ¬ì˜¬ ë•Œ ì‚¬ìš©)
        """
        # ëœë¤ ë²ˆí˜¸ ìƒì„± (íŒŒì¼ëª…ì— ì‚¬ìš©)
        self.rnd_num = rnd.randint(100, 999)
        
        # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
        self.cur_dir = os.getcwd()  # í˜„ì¬ í´ë” ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        self.data_dir = self.cur_dir+'\\data\\'  # ë°ì´í„° í´ë” ê²½ë¡œ (ì…ì°° ë°ì´í„°ê°€ ìˆëŠ” ê³³)
        self.save_dir = self.cur_dir+'\\res\\'  # ê²°ê³¼ ì €ì¥ í´ë” (ëª¨ë¸ íŒŒì¼ë“¤ì´ ìˆëŠ” ê³³)
        self.save_filename = saved_filenm  # ì €ì¥í•  íŒŒì¼ëª…
        
        # Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.kiwi = None
        self.kiwi = self.CreateKiwi(saved_filenm)  # Kiwi ê°ì²´ ìƒì„±
    
    def save(self, filename):
        joblib.dump(self.kiwi._user_values, self.save_dir+filename)
        return self
    
    def load(self, filename):
        o = joblib.load(self.save_dir+filename)
        return o
        
    def loadDictonary(self, filename, max_rows: int = 30000, log_every: int = 2000):
        """
        ëŒ€ìš©ëŸ‰ ì‚¬ìš©ì ì‚¬ì „ êµ¬ì¶• ìµœì í™”: ìƒí•œì„ (cap)ê³¼ ì§„í–‰ ë¡œê·¸ë¥¼ ì¶”ê°€í•´ ì¥ì‹œê°„ ë¸”ë¡œí‚¹ì„ ë°©ì§€í•œë‹¤.
        """
        full_path = self.data_dir+filename
        if not os.path.exists(full_path):
            print(f"âš ï¸  ì‚¬ìš©ì ì‚¬ì „ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {full_path}")
            return

        try:
            self.data = pd.read_csv(full_path, nrows=max_rows)
        except Exception as e:
            print(f"âš ï¸  ì‚¬ìš©ì ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return

        if "ë‹¨ì–´" not in self.data.columns:
            print("âš ï¸  'ë‹¨ì–´' ì»¬ëŸ¼ì´ ì—†ì–´ ì‚¬ìš©ì ì‚¬ì „ì„ êµ¬ì¶•í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"ğŸ“˜ ì‚¬ìš©ì ì‚¬ì „ ë‹¨ì–´ ì¶”ê°€ ì‹œì‘ (ìµœëŒ€ {len(self.data)}ê±´)")
        for i, row in enumerate(self.data.itertuples(index=False)):
            try:
                self.kiwi.add_user_word(getattr(row, "ë‹¨ì–´"), 'NNP')
            except KeyboardInterrupt:
                print("â¹ï¸  ì‚¬ìš©ì ì¤‘ë‹¨ìœ¼ë¡œ ì‚¬ì „ êµ¬ì¶•ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.")
                break
            except Exception:
                # ê°œë³„ ë‹¨ì–´ ì¶”ê°€ ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ì§„í–‰
                pass
            if (i+1) % log_every == 0:
                print(f"   - ì§„í–‰: {i+1} / {len(self.data)}")
        print("âœ… ì‚¬ìš©ì ì‚¬ì „ ë‹¨ì–´ ì¶”ê°€ ì™„ë£Œ")
    
    def CreateKiwi(self, saved_filenm):
        o = None
        if(self.kiwi is None):
            if(saved_filenm is None):
                o = Kiwi(num_workers=8)
            else:
                o = Kiwi(num_workers=8)
                # ì €ì¥ëœ ì‚¬ìš©ì ì‚¬ì „ì„ ë¡œë“œí•  ë•ŒëŠ” íŒŒì¼ëª…ë§Œ ì „ë‹¬ (load ë‚´ë¶€ì—ì„œ ê²½ë¡œ ê²°í•©)
                o._user_values = self.load(saved_filenm)
                #o.load_user_dictionary(self.save_dir+saved_filenm)
        
        return o
            
    def cleared_line(self, line):
        # numpy.float64ë‚˜ NaN ê°’ ì²˜ë¦¬
        if pd.isna(line) or line is None:
            line = ''
        else:
            line = str(line).lower().replace('(', ' ').replace(')', ' ').replace('n/a', '')
        
        nm_words = []
        tokens = self.kiwi.tokenize(line)
        for token in tokens:
            if token.tag in ['MM', 'NNG', 'NNB', 'NNP', 'SL', 'XPN', 'MAG', 'SN', 'SO', 'W_SERIAL']:
                nm_words.append(token.form)
                
        return ' '.join(nm_words)
    
    def cleared_lines_from(self, orglines):
        lines = []
        for line in orglines:
            lines.append(self.cleared_line(line))
        
        return lines      
    
    def get_key(self, voca, val):
      
        for key, value in voca.items():
            if val == value:
                return key
    
        return "key doesn't exist"
    
    def conv_words(self, voca, vals):
        ret = []
        for val in vals:
            for key, value in voca.items():
                if val == value:
                    ret.append(key)
            
            
        return " ".join(ret)
    
    
    def nn_only(self, orglines):
        lines = []
        for key in orglines:
            # numpy.float64ë‚˜ NaN ê°’ ì²˜ë¦¬
            if pd.isna(key) or key is None:
                key = ''
            else:
                key = str(key).lower().replace('(', ' ').replace(')', ' ').replace('n/a', '')
            
            nm_words = []
            tokens = self.kiwi.tokenize(key)
            #print(key, tokens)
            for token in tokens:
                if token.tag in ['MM', 'NNG', 'NNB', 'NNP', 'SL', 'XPN', 'MAG', 'SN', 'SO', 'W_SERIAL']:
                    nm_words.append(token.form)
            lines.append(' '.join(nm_words))
            
        return lines


class KiwiVectorizer():
    def __init__(self):
        self.rnd_num = rnd.randint(100, 999)
        
        self.cur_dir = os.getcwd()
        self.save_dir = self.cur_dir+'\\res\\'
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ íŒŒë¼ë¯¸í„° ìµœì í™”
        self.vect = TfidfVectorizer(
            ngram_range=(1, 1), 
            token_pattern='(?u)\\b\\w+\\b',
            max_features=5000,  # ìµœëŒ€ íŠ¹ì„± ìˆ˜ ì œí•œ
            min_df=2,           # ìµœì†Œ ë¬¸ì„œ ë¹ˆë„ (2íšŒ ì´ìƒ ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ë§Œ)
            max_df=0.95,        # ìµœëŒ€ ë¬¸ì„œ ë¹ˆë„ (95% ì´ìƒ ë¬¸ì„œì— ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ ì œì™¸)
            sublinear_tf=True   # TF ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
        )
    
    def load(self, filename):
        voca = joblib.load(self.save_dir + filename)
        self.vect.vocabulary_ = voca["vocabulary"] 
        self.vect.idf_ = voca["idf"]
    
    def save(self, filename):
        joblib.dump({'vocabulary':self.vect.vocabulary_, 'idf':self.vect.idf_}, self.save_dir + filename)
        print("ë‹¨ì–´ì‚¬ì „ íŒŒì¼("+filename+")ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ")
    
    def fit(self, lines):
        return self.vect.fit(lines)
    
    def transform(self, lines):
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ toarray() ì—†ì´ CSR í–‰ë ¬ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return self.vect.transform(lines)
    
    def scores(self, lines):
        return self.toValues(self.transform(lines))


    def toValues(self, csrmat:csr_matrix):
        lst = []
        safty_sz = len(csrmat.indptr)-1
        for i, n in enumerate(csrmat.indptr):
            sumval = 0
            if i<safty_sz:
                indiceVal = csrmat.indices[csrmat.indptr[i]:csrmat.indptr[i+1]]
                dataVal = csrmat.data[csrmat.indptr[i]:csrmat.indptr[i+1]]
                for j, va1 in enumerate(indiceVal):
                    sumval += va1 * dataVal[j]
                
                lst.append(sumval)
        return lst


class BidLowerMarginRateTrain():
    """
    ì…ì°° íˆ¬ì°°ë¥  ì˜ˆì¸¡ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ë©”ì¸ í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ì˜ ì—­í• :
    1. ì¡°ë‹¬ì²­ ì…ì°° ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì „ì²˜ë¦¬
    2. í…ìŠ¤íŠ¸ ë°ì´í„°(í‚¤ì›Œë“œ, ê¸°ê´€ëª…, ì§€ì—­)ë¥¼ ìˆ«ìë¡œ ë³€í™˜
    3. 3ê°œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ í›ˆë ¨
       - ëª¨ë¸1: ì—…ì²´ íˆ¬ì°°ë¥  ì˜ˆì¸¡ (XGBoost)
       - ëª¨ë¸2: ì˜ˆê°€ íˆ¬ì°°ë¥  ì˜ˆì¸¡ (LightGBM)  
       - ëª¨ë¸3: ì°¸ì—¬ ì—…ì²´ ìˆ˜ ì˜ˆì¸¡ (GradientBoostingRegressor)
    4. í›ˆë ¨ëœ ëª¨ë¸ê³¼ ì „ì²˜ë¦¬ ë„êµ¬ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
    5. ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì¶œë ¥
    
    ë¨¸ì‹ ëŸ¬ë‹ ê³¼ì •:
    1. ë°ì´í„° ë¡œë“œ â†’ 2. í…ìŠ¤íŠ¸ ë²¡í„°í™” â†’ 3. ë°ì´í„° ì •ê·œí™” â†’ 4. ëª¨ë¸ í›ˆë ¨ â†’ 5. ëª¨ë¸ ì €ì¥
    """
    
    def __init__(self):
        """
        BidLowerMarginRateTrain ì´ˆê¸°í™” í•¨ìˆ˜
        - ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
        - ë°ì´í„° ì»¬ëŸ¼ ì •ì˜
        - í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë„êµ¬ë“¤ ì´ˆê¸°í™”
        """
        # ëœë¤ ë²ˆí˜¸ ìƒì„± (íŒŒì¼ëª…ì— ì‚¬ìš©)
        self.rnd_num = rnd.randint(100, 999)
        
        # ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
        self.cur_dir = os.getcwd()  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
        self.data_dir = self.cur_dir+'\\data\\'  # ë°ì´í„° í´ë” (ì…ì°° ë°ì´í„°ê°€ ìˆëŠ” ê³³)
        self.save_dir = self.cur_dir+'\\res\\'  # ê²°ê³¼ ì €ì¥ í´ë” (ëª¨ë¸ íŒŒì¼ë“¤ì´ ì €ì¥ë  ê³³)
        
        # ê²°ê³¼ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ë‚˜ì¤‘ì— ë°ì´í„° í¬ê¸°ì™€ í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ì— ë”°ë¼ ìƒì„±)
        self.excel_file_nm = None  # ê²°ê³¼ ì—‘ì…€ íŒŒì¼ëª… (ë‚˜ì¤‘ì— ì„¤ì •)
        self.xlxs_dir = None  # ì—‘ì…€ íŒŒì¼ ì „ì²´ ê²½ë¡œ (ë‚˜ì¤‘ì— ì„¤ì •) 
        
       
        # ===== ë°ì´í„° ì»¬ëŸ¼ ì •ì˜ =====
        # CSV íŒŒì¼ì—ì„œ ì½ì–´ì˜¬ ì»¬ëŸ¼ë“¤ì˜ ì´ë¦„ ì •ì˜
        self.cvs_columns = ['ê¸°ì´ˆê¸ˆì•¡', 'ë‚™ì°°í•˜í•œë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜', 
                            'ë‚™ì°°ê¸ˆì•¡', 'ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'íˆ¬ì°°ë¥ ì˜¤ì°¨', 
                            'ê°„ì ‘ë¹„', 'ìˆœê³µì‚¬ì›ê°€', 'ì…ì°°ë²ˆí˜¸', 'ì…ì°°ì°¨ìˆ˜', 
                            'ì˜ˆì •ê¸ˆì•¡', 'ë‚™ì°°í•˜í•œê°€', 
                            'ë©´í—ˆì œí•œì½”ë“œ','ê³µê³ ê¸°ê´€ì½”ë“œ','ì£¼ê³µì¢…ëª…', 
                            'ê³µê³ ê¸°ê´€ëª…', 'ê³µê³ ê¸°ê´€ì ìˆ˜',
                            'ê³µì‚¬ì§€ì—­', 'ê³µì‚¬ì§€ì—­ì ìˆ˜',
                            'í‚¤ì›Œë“œ', 'í‚¤ì›Œë“œì ìˆ˜']
        
        # ê° ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì… ì •ì˜ (pandasê°€ ì˜¬ë°”ë¥´ê²Œ ë°ì´í„°ë¥¼ ì½ê¸° ìœ„í•´)
        self.cvs_columns_type = {
                            'ê¸°ì´ˆê¸ˆì•¡':'float64', 'ë‚™ì°°í•˜í•œë¥ ':'float64', 'ì°¸ì—¬ì—…ì²´ìˆ˜':'float64', 
                            'ë‚™ì°°ê¸ˆì•¡':'int64', 'ì—…ì²´íˆ¬ì°°ë¥ ':'float64', 'ì˜ˆê°€íˆ¬ì°°ë¥ ':'float64', 'íˆ¬ì°°ë¥ ì˜¤ì°¨':'float64', 
                            'ê°„ì ‘ë¹„':'int64', 'ìˆœê³µì‚¬ì›ê°€':'int64', 'ì…ì°°ë²ˆí˜¸':'str', 'ì…ì°°ì°¨ìˆ˜':'int64', 
                            'ì˜ˆì •ê¸ˆì•¡':'int64', 'ë‚™ì°°í•˜í•œê°€':'int64',
                            'ë©´í—ˆì œí•œì½”ë“œ':'str','ê³µê³ ê¸°ê´€ì½”ë“œ':'str','ì£¼ê³µì¢…ëª…':'str', 
                            'ê³µê³ ê¸°ê´€ëª…':'str', 'ê³µê³ ê¸°ê´€ì ìˆ˜':'float64',
                            'ê³µì‚¬ì§€ì—­':'str', 'ê³µì‚¬ì§€ì—­ì ìˆ˜':'float64',
                            'í‚¤ì›Œë“œ':'str', 'í‚¤ì›Œë“œì ìˆ˜':'float64'
                            }
        
        # ===== ê²°ê³¼ ë°ì´í„° ì»¬ëŸ¼ ì •ì˜ =====
        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ì—‘ì…€ íŒŒì¼ì˜ ì»¬ëŸ¼ë“¤ ì •ì˜ (ì›ë³¸ ë°ì´í„° + ì˜ˆì¸¡ ê²°ê³¼)
        self.result_columns = ['ì…ì°°ë²ˆí˜¸', 'ì…ì°°ì°¨ìˆ˜', 'ê¸°ì´ˆê¸ˆì•¡', 
                               'ë‚™ì°°í•˜í•œë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜', 'ê°„ì ‘ë¹„', 'ìˆœê³µì‚¬ì›ê°€', 
                               'ë©´í—ˆì œí•œì½”ë“œ', 'ê³µê³ ê¸°ê´€ì½”ë“œ',
                               'ê³µê³ ê¸°ê´€ëª…', 'ê³µê³ ê¸°ê´€ì ìˆ˜',
                               'ê³µì‚¬ì§€ì—­', 'ê³µì‚¬ì§€ì—­ì ìˆ˜',                               
                               'í‚¤ì›Œë“œ', 'í‚¤ì›Œë“œì ìˆ˜',
                               'ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'íˆ¬ì°°ë¥ ì˜¤ì°¨', 
                               'ì˜ˆì •ê¸ˆì•¡', 'ë‚™ì°°í•˜í•œê°€', 'ë‚™ì°°ê¸ˆì•¡', 
                               'ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡', 'ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡', 'ì°¸ì—¬ì—…ì²´ìˆ˜ì˜ˆì¸¡', 'ì˜ˆì •ê¸ˆì•¡ì˜ˆì¸¡',
                               'ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡', 'Aê°’ì—¬ë¶€', 'ê²°ê³¼1', 
                               'ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡', 'ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨', 'ê²°ê³¼2']
        
        # ê²°ê³¼ ì»¬ëŸ¼ë“¤ì˜ ë°ì´í„° íƒ€ì… ì •ì˜
        self.result_columns_type = {
                            'ì…ì°°ë²ˆí˜¸':'str', 'ì…ì°°ì°¨ìˆ˜':'int64','ê¸°ì´ˆê¸ˆì•¡':'float64',
                            'ë‚™ì°°í•˜í•œë¥ ':'float64', 'ì°¸ì—¬ì—…ì²´ìˆ˜':'float64', 'ê°„ì ‘ë¹„':'int64', 'ìˆœê³µì‚¬ì›ê°€':'int64',  
                            'ë©´í—ˆì œí•œì½”ë“œ':'float64', 'ê³µê³ ê¸°ê´€ì½”ë“œ':'float64',
                            'ê³µê³ ê¸°ê´€ëª…':'str', 'ê³µê³ ê¸°ê´€ì ìˆ˜':'float64',
                            'ê³µì‚¬ì§€ì—­':'str', 'ê³µì‚¬ì§€ì—­ì ìˆ˜':'float64',                            
                            'í‚¤ì›Œë“œ':'str', 'í‚¤ì›Œë“œì ìˆ˜':'float64',
                            'ì—…ì²´íˆ¬ì°°ë¥ ':'float64', 'ì˜ˆê°€íˆ¬ì°°ë¥ ':'float64', 'íˆ¬ì°°ë¥ ì˜¤ì°¨':'float64', 
                            'ì˜ˆì •ê¸ˆì•¡':'int64', 'ë‚™ì°°í•˜í•œê°€':'int64', 'ë‚™ì°°ê¸ˆì•¡':'int64', 
                            'ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡':'float64', 'ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡':'float64', 'ì°¸ì—¬ì—…ì²´ìˆ˜ì˜ˆì¸¡':'float64', 'ì˜ˆì •ê¸ˆì•¡ì˜ˆì¸¡':'int64',
                            'ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡':'float64', 'Aê°’ì—¬ë¶€':'str', 'ê²°ê³¼1':'str',
                            'ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡':'float64', 'ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨':'float64', 'ê²°ê³¼2':'str'
                            }

        
        # ===== í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë„êµ¬ë“¤ ì´ˆê¸°í™” =====
        # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” (ìºì‹œ ì‚¬ìš©: ì¡´ì¬ ì‹œ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒì„± í›„ ì €ì¥)
        tok_cache_filename = 'gb.tokenizer.v0.1.1.npz'
        if os.path.exists(self.save_dir + tok_cache_filename):
            print("âœ… ì‚¬ìš©ì ì‚¬ì „ ìºì‹œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
            self.tokenizer = KiwiTokenizer(tok_cache_filename)
        else:
            print("ğŸ“˜ ì‚¬ìš©ì ì‚¬ì „ì„ ìµœì´ˆ êµ¬ì¶•í•©ë‹ˆë‹¤ (ìµœì´ˆ 1íšŒë§Œ ìˆ˜í–‰).")
            self.tokenizer = KiwiTokenizer(None)
            # ëŒ€ìš©ëŸ‰ êµ¬ì¶• ì‹œ ì¥ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆì–´ ì¼ë¶€ë§Œ ë¡œë“œí•˜ë„ë¡ ìµœì í™”
            self.tokenizer.loadDictonary('í‘œì¤€êµ­ì–´ëŒ€ì‚¬ì „.NNP.csv')  # í‘œì¤€êµ­ì–´ëŒ€ì‚¬ì „ì„ ë¡œë“œí•˜ì—¬ ì •í™•í•œ ë‹¨ì–´ ì¸ì‹
            self.tokenizer.save(tok_cache_filename)
        
        # TF-IDF ë²¡í„°í™”ê¸° ì´ˆê¸°í™” (í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬)
        self.vectorizer = KiwiVectorizer()

    def generateExcelFileName(self, data_size, test_ratio):
        """
        ë°ì´í„° í¬ê¸°ì™€ í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ì— ë”°ë¼ ì—‘ì…€ íŒŒì¼ëª…ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            data_size (int): ì „ì²´ ë°ì´í„° í¬ê¸°
            test_ratio (float): í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨ (0.0 ~ 1.0)
            
        Returns:
            str: ìƒì„±ëœ íŒŒì¼ëª… (result-yyMMddMMss-ë°ì´í„°ê°¯ìˆ˜-í…ŒìŠ¤íŠ¸ë¹„ìœ¨.xlsx)
            
        íŒŒì¼ëª… ê·œì¹™:
        - result-yyMMddMMss-ë°ì´í„°ê°¯ìˆ˜-í…ŒìŠ¤íŠ¸ë¹„ìœ¨.xlsx
        - ì˜ˆ: result-2412011430-5-8515.xlsx (2024ë…„ 12ì›” 1ì¼ 14ì‹œ 30ë¶„, 5ë§Œê°œ ë°ì´í„°, 85:15 ë¹„ìœ¨)
        """
        from datetime import datetime
        
        # í˜„ì¬ ì‹œê°„ì„ yyMMddMMss í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        now = datetime.now()
        time_str = now.strftime("%y%m%d%H%M")
        
        # ë°ì´í„° í¬ê¸°ë¥¼ ë§Œê°œ ë‹¨ìœ„ë¡œ ë³€í™˜
        if data_size < 50000:
            data_unit = 1  # 5ë§Œê°œ ë¯¸ë§Œì€ 1ë¡œ í‘œì‹œ
        elif data_size < 100000:
            data_unit = 5  # 5ë§Œ~10ë§Œê°œëŠ” 5ë¡œ í‘œì‹œ
        elif data_size < 300000:
            data_unit = 10  # 10ë§Œ~30ë§Œê°œëŠ” 10ìœ¼ë¡œ í‘œì‹œ
        else:
            data_unit = 30  # 30ë§Œê°œ ì´ìƒì€ 30ìœ¼ë¡œ í‘œì‹œ
        
        # í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ì„ ì •ìˆ˜ë¡œ ë³€í™˜ (ì˜ˆ: 0.15 -> 15, 0.2 -> 20)
        train_ratio = int((1 - test_ratio) * 100)
        test_ratio_int = int(test_ratio * 100)
        ratio_str = f"{train_ratio}{test_ratio_int:02d}"  # 8515, 8020 ë“±
        
        # íŒŒì¼ëª… ìƒì„±
        filename = f"result-{time_str}-{data_unit}-{ratio_str}.xlsx"
        
        return filename

    
    def make_result_dataframe2(self, xx_test, result1, result2, result3):
        df_rst = pd.DataFrame(columns = self.result_columns)
        df_rst.astype(self.result_columns_type)        
        
        selected_cols = ['ì…ì°°ë²ˆí˜¸', 'ì…ì°°ì°¨ìˆ˜', 
                         'ê¸°ì´ˆê¸ˆì•¡', 'ë‚™ì°°í•˜í•œë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜', 'ê°„ì ‘ë¹„', 'ìˆœê³µì‚¬ì›ê°€', 
                         'ë©´í—ˆì œí•œì½”ë“œ', 'ê³µê³ ê¸°ê´€ì½”ë“œ', 
                         'í‚¤ì›Œë“œ', 'í‚¤ì›Œë“œì ìˆ˜', 
                         'ê³µê³ ê¸°ê´€ëª…', 'ê³µê³ ê¸°ê´€ì ìˆ˜',
                         'ê³µì‚¬ì§€ì—­', 'ê³µì‚¬ì§€ì—­ì ìˆ˜',                             
                         'ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'íˆ¬ì°°ë¥ ì˜¤ì°¨', 
                         'ì˜ˆì •ê¸ˆì•¡', 'ë‚™ì°°í•˜í•œê°€', 'ë‚™ì°°ê¸ˆì•¡']
        
        df_xx_test = pd.DataFrame(xx_test, columns = self.cvs_columns)
        df_test = pd.DataFrame(df_xx_test, columns = selected_cols)
        
        print("ì˜ˆì¸¡ê²°ê³¼ê°’ ì…ë ¥ ì‹œì‘")
        
        for i, v in enumerate(selected_cols):
            df_rst[v] = df_test[v]
                
        df_rst["ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡"] = result1
        df_rst["ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡"] = result2
        df_rst["ì°¸ì—¬ì—…ì²´ìˆ˜ì˜ˆì¸¡"] = result3
        
        # ì˜ˆê°€íˆ¬ì°°ë¥  ì˜ˆì¸¡ê°’ìœ¼ë¡œë¶€í„° ì˜ˆì •ê¸ˆì•¡ ì—­ì‚° ê³„ì‚°
        # ì˜ˆê°€íˆ¬ì°°ë¥  = (ì˜ˆì •ê¸ˆì•¡ / ê¸°ì´ˆê¸ˆì•¡) * ë‚™ì°°í•˜í•œë¥ 
        # ë”°ë¼ì„œ ì˜ˆì •ê¸ˆì•¡ = (ì˜ˆê°€íˆ¬ì°°ë¥  * ê¸°ì´ˆê¸ˆì•¡) / ë‚™ì°°í•˜í•œë¥ 
        df_rst["ì˜ˆì •ê¸ˆì•¡ì˜ˆì¸¡"] = (df_rst["ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡"] * df_rst["ê¸°ì´ˆê¸ˆì•¡"]) / df_rst["ë‚™ì°°í•˜í•œë¥ "]
        
        # ===== ìƒˆë¡œìš´ ì»¬ëŸ¼ë“¤ ê³„ì‚° =====
        # ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡ = ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡ * ê¸°ì´ˆê¸ˆì•¡
        df_rst["ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡"] = df_rst["ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡"] * df_rst["ê¸°ì´ˆê¸ˆì•¡"]
        
        # Aê°’ì—¬ë¶€: ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡ì´ 0.8 ì´ìƒì´ë©´ 'O', ì•„ë‹ˆë©´ ë¹ˆ ë¬¸ìì—´
        df_rst["Aê°’ì—¬ë¶€"] = df_rst["ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡"].apply(lambda x: 'O' if x >= 0.8 else '')
        
        # ê²°ê³¼1: ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡ì´ ë‚™ì°°í•˜í•œê°€ë³´ë‹¤ ì‘ìœ¼ë©´ "ë‚™ì°°í•˜í•œì„ ë¯¸ë‹¬", 
        # ë‚™ì°°í•˜í•œê°€ ì´ìƒì´ê³  ë‚™ì°°ê¸ˆì•¡ ë¯¸ë§Œì´ë©´ "ë‚™ì°°", ì•„ë‹ˆë©´ "-"
        def calculate_result1(row):
            predicted_amount = row["ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡"]
            min_bid = row["ë‚™ì°°í•˜í•œê°€"]
            actual_amount = row["ë‚™ì°°ê¸ˆì•¡"]
            
            if predicted_amount < min_bid:
                return "ë‚™ì°°í•˜í•œì„ ë¯¸ë‹¬"
            elif predicted_amount >= min_bid and predicted_amount < actual_amount:
                return "ë‚™ì°°"
            else:
                return "-"
        
        df_rst["ê²°ê³¼1"] = df_rst.apply(calculate_result1, axis=1)
        
        # ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡ = ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡ / ë‚™ì°°í•˜í•œë¥  * ê¸°ì´ˆê¸ˆì•¡
        df_rst["ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡"] = (df_rst["ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡"] / df_rst["ë‚™ì°°í•˜í•œë¥ "]) * df_rst["ê¸°ì´ˆê¸ˆì•¡"]
        
        # ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨ = ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡ * ë‚™ì°°í•˜í•œë¥ 
        df_rst["ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨"] = df_rst["ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡"] * df_rst["ë‚™ì°°í•˜í•œë¥ "]
        
        # ê²°ê³¼2: ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨ì´ ë‚™ì°°í•˜í•œê°€ë³´ë‹¤ ì‘ìœ¼ë©´ "ë‚™ì°°í•˜í•œì„ ë¯¸ë‹¬",
        # ë‚™ì°°í•˜í•œê°€ ì´ìƒì´ê³  ë‚™ì°°ê¸ˆì•¡ ë¯¸ë§Œì´ë©´ "ë‚™ì°°", ì•„ë‹ˆë©´ "-"
        def calculate_result2(row):
            predicted_amount = row["ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨"]
            min_bid = row["ë‚™ì°°í•˜í•œê°€"]
            actual_amount = row["ë‚™ì°°ê¸ˆì•¡"]
            
            if predicted_amount < min_bid:
                return "ë‚™ì°°í•˜í•œì„ ë¯¸ë‹¬"
            elif predicted_amount >= min_bid and predicted_amount < actual_amount:
                return "ë‚™ì°°"
            else:
                return "-"
        
        df_rst["ê²°ê³¼2"] = df_rst.apply(calculate_result2, axis=1)
        
        print("ì˜ˆì¸¡ê²°ê³¼í…Œì´ë¸” ì‘ì„±ì™„ë£Œ")
         
        return df_rst


    
    def arrayToDataFrame(self, data, cols):
        df = pd.DataFrame(pd.DataFrame(data), columns=cols)
        return df
    

    def loadTrainsetFromFile(self, filename):
        """
        CSV íŒŒì¼ì—ì„œ ì…ì°° ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            filename (str): ë¶ˆëŸ¬ì˜¬ CSV íŒŒì¼ëª…
            
        Returns:
            tuple: (x_train, x_test, y_train, y_test) - í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°
            
        ì²˜ë¦¬ ê³¼ì •:
        1. CSV íŒŒì¼ ì½ê¸°
        2. í…ìŠ¤íŠ¸ ë°ì´í„°(í‚¤ì›Œë“œ, ê¸°ê´€ëª…, ì§€ì—­)ë¥¼ TF-IDF ì ìˆ˜ë¡œ ë³€í™˜
        3. í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„í• 
        4. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ë°˜í™˜
        """
        print("ì›ì‹œ í›ˆë ¨ë°ì´íƒ€ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
        #'bid_v5_202412311021.csv'
        data = pd.read_csv(self.data_dir+filename)   # CSV íŒŒì¼ ì½ê¸° (ì˜ˆ: bid_250914.csv)
        
        
        print("ì´ ë°ì´íƒ€ìˆ˜: "+str(len(data))+'ê±´')
        
        print("="*80)
        print("í•™ìŠµì…‹ê³¼ í…ŒìŠ¤íŠ¸ì…‹ ë¶„ë¦¬")
        print(f"ì „ì²´ ë°ì´í„°: {len(data)}ê°œ")
        
        # ===== ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ë™ì  í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ ì„¤ì • =====
        data_size = len(data)
        if data_size < 20000:
            test_ratio = 0.2  # 20% - 2ë§Œê°œ ë¯¸ë§Œ
            ratio_desc = "80:20 (ì†Œê·œëª¨ ë°ì´í„°)"
        elif data_size < 50000:
            test_ratio = 0.15  # 15% - 2ë§Œ~5ë§Œê°œ
            ratio_desc = "85:15 (ì¤‘ì†Œê·œëª¨ ë°ì´í„°)"
        elif data_size < 100000:
            test_ratio = 0.1   # 10% - 5ë§Œ~10ë§Œê°œ
            ratio_desc = "90:10 (ì¤‘ê·œëª¨ ë°ì´í„°)"
        else:
            test_ratio = 0.05  # 5% - 10ë§Œê°œ ì´ìƒ
            ratio_desc = "95:5 (ëŒ€ê·œëª¨ ë°ì´í„°)"
        
        train_count = int(data_size * (1 - test_ratio))
        test_count = data_size - train_count
        
        print(f"ì ìš© ë¹„ìœ¨: {ratio_desc}")
        print(f"í›ˆë ¨ ë°ì´í„°: {train_count:,}ê°œ ({((1-test_ratio)*100):.0f}%)")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_count:,}ê°œ ({test_ratio*100:.0f}%)")
        print("="*80)
        
        # ===== ì…ë ¥ ë°ì´í„°(X) ì¤€ë¹„ =====
        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ë§Œ ì„ íƒí•˜ì—¬ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        dataset_x = pd.DataFrame(data, columns = self.cvs_columns)
        
        # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ë“¤ì„ ë¨¼ì € ë¬¸ìì—´ë¡œ ë³€í™˜
        print("í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ ì¤‘...")
        if 'í‚¤ì›Œë“œ' in dataset_x.columns:
            dataset_x['í‚¤ì›Œë“œ'] = dataset_x['í‚¤ì›Œë“œ'].fillna('').astype(str)
            dataset_x['í‚¤ì›Œë“œ'] = dataset_x['í‚¤ì›Œë“œ'].replace(['nan', 'NaN', 'None', 'null'], '')
        if 'ê³µê³ ê¸°ê´€ëª…' in dataset_x.columns:
            dataset_x['ê³µê³ ê¸°ê´€ëª…'] = dataset_x['ê³µê³ ê¸°ê´€ëª…'].fillna('').astype(str)
            dataset_x['ê³µê³ ê¸°ê´€ëª…'] = dataset_x['ê³µê³ ê¸°ê´€ëª…'].replace(['nan', 'NaN', 'None', 'null'], '')
        if 'ê³µì‚¬ì§€ì—­' in dataset_x.columns:
            dataset_x['ê³µì‚¬ì§€ì—­'] = dataset_x['ê³µì‚¬ì§€ì—­'].fillna('').astype(str)
            dataset_x['ê³µì‚¬ì§€ì—­'] = dataset_x['ê³µì‚¬ì§€ì—­'].replace(['nan', 'NaN', 'None', 'null'], '')
        
        # ë¬¸ìì—´ ì»¬ëŸ¼ë“¤ì„ ìˆ«ìë¡œ ë³€í™˜
        print("ë¬¸ìì—´ ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜ ì¤‘...")
        
        # ë©´í—ˆì œí•œì½”ë“œë¥¼ ìˆ«ìë¡œ ë³€í™˜ (ë¬¸ìì—´ì„ í•´ì‹œê°’ìœ¼ë¡œ ë³€í™˜)
        if 'ë©´í—ˆì œí•œì½”ë“œ' in dataset_x.columns:
            dataset_x['ë©´í—ˆì œí•œì½”ë“œ'] = dataset_x['ë©´í—ˆì œí•œì½”ë“œ'].astype(str).apply(lambda x: hash(x) % 1000000 if pd.notna(x) and x != 'nan' else 0)
        
        # ê³µê³ ê¸°ê´€ì½”ë“œë¥¼ ìˆ«ìë¡œ ë³€í™˜
        if 'ê³µê³ ê¸°ê´€ì½”ë“œ' in dataset_x.columns:
            dataset_x['ê³µê³ ê¸°ê´€ì½”ë“œ'] = dataset_x['ê³µê³ ê¸°ê´€ì½”ë“œ'].astype(str).apply(lambda x: hash(x) % 1000000 if pd.notna(x) and x != 'nan' else 0)
        
        # ê° ì»¬ëŸ¼ì˜ ë°ì´í„° íƒ€ì…ì„ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •
        dataset_x.astype(self.cvs_columns_type)
        
        
        # ===== í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ =====
        # ê° í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ í˜•íƒœì†Œ ë¶„ì„í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ë§Œ ì¶”ì¶œ
        print("í‚¤ì›Œë“œ ì»¬ëŸ¼ ë°ì´í„° íƒ€ì… ë° ìƒ˜í”Œ:")
        print(f"í‚¤ì›Œë“œ ì»¬ëŸ¼ íƒ€ì…: {dataset_x['í‚¤ì›Œë“œ'].dtype}")
        print(f"í‚¤ì›Œë“œ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ): {dataset_x['í‚¤ì›Œë“œ'].head(10).tolist()}")
        print(f"í‚¤ì›Œë“œ NaN ê°œìˆ˜: {dataset_x['í‚¤ì›Œë“œ'].isna().sum()}")
        
        print("\nê³µê³ ê¸°ê´€ëª… ì»¬ëŸ¼ ë°ì´í„° íƒ€ì… ë° ìƒ˜í”Œ:")
        print(f"ê³µê³ ê¸°ê´€ëª… ì»¬ëŸ¼ íƒ€ì…: {dataset_x['ê³µê³ ê¸°ê´€ëª…'].dtype}")
        print(f"ê³µê³ ê¸°ê´€ëª… ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ): {dataset_x['ê³µê³ ê¸°ê´€ëª…'].head(10).tolist()}")
        print(f"ê³µê³ ê¸°ê´€ëª… NaN ê°œìˆ˜: {dataset_x['ê³µê³ ê¸°ê´€ëª…'].isna().sum()}")
        print(f"ê³µê³ ê¸°ê´€ëª… ê³ ìœ ê°’ ê°œìˆ˜: {dataset_x['ê³µê³ ê¸°ê´€ëª…'].nunique()}")
        
        print("\nê³µì‚¬ì§€ì—­ ì»¬ëŸ¼ ë°ì´í„° íƒ€ì… ë° ìƒ˜í”Œ:")
        print(f"ê³µì‚¬ì§€ì—­ ì»¬ëŸ¼ íƒ€ì…: {dataset_x['ê³µì‚¬ì§€ì—­'].dtype}")
        print(f"ê³µì‚¬ì§€ì—­ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ): {dataset_x['ê³µì‚¬ì§€ì—­'].head(10).tolist()}")
        print(f"ê³µì‚¬ì§€ì—­ NaN ê°œìˆ˜: {dataset_x['ê³µì‚¬ì§€ì—­'].isna().sum()}")
        
        lines = self.tokenizer.nn_only(np.squeeze(dataset_x["í‚¤ì›Œë“œ"].tolist()))      # í‚¤ì›Œë“œ ì²˜ë¦¬
        lines2 = self.tokenizer.nn_only(np.squeeze(dataset_x["ê³µê³ ê¸°ê´€ëª…"].tolist()))  # ê³µê³ ê¸°ê´€ëª… ì²˜ë¦¬
        lines3 = self.tokenizer.nn_only(np.squeeze(dataset_x["ê³µì‚¬ì§€ì—­"].tolist()))    # ê³µì‚¬ì§€ì—­ ì²˜ë¦¬
        
        # ì²˜ë¦¬ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 10ê°œ)
        print("í‚¤ì›Œë“œ ì²˜ë¦¬ ê²°ê³¼:")
        print(lines[:10])
        print("ê³µê³ ê¸°ê´€ëª… ì²˜ë¦¬ ê²°ê³¼:")
        print(lines2[:10])
        print("ê³µì‚¬ì§€ì—­ ì²˜ë¦¬ ê²°ê³¼:")
        print(lines3[:10])
        
        # ===== TF-IDF ë²¡í„°í™”ê¸° í•™ìŠµ =====
        # ëª¨ë“  í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•©ì³ì„œ ë‹¨ì–´ì‚¬ì „ì„ í•™ìŠµ
        all_text = lines + lines2 + lines3
        print(f"ì „ì²´ í…ìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(all_text)}")
        print(f"ë¹ˆ ë¬¸ìì—´ ê°œìˆ˜: {sum(1 for text in all_text if text.strip() == '')}")
        
        # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ
        non_empty_text = [text for text in all_text if text.strip() != '']
        print(f"ë¹„ì–´ìˆì§€ ì•Šì€ í…ìŠ¤íŠ¸ ìˆ˜: {len(non_empty_text)}")
        
        if len(non_empty_text) > 0:
            self.vectorizer.fit(non_empty_text)
        else:
            # ëª¨ë“  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆë‹¤ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ í•™ìŠµ
            self.vectorizer.fit(['ê¸°ë³¸í‚¤ì›Œë“œ'])
        
        # ===== í…ìŠ¤íŠ¸ë¥¼ TF-IDF ì ìˆ˜ë¡œ ë³€í™˜ =====
        pts = self.vectorizer.scores(lines)      # í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        pts2 = self.vectorizer.scores(lines2)    # ê³µê³ ê¸°ê´€ëª… ì ìˆ˜ ê³„ì‚°
        pts3 = self.vectorizer.scores(lines3)    # ê³µì‚¬ì§€ì—­ ì ìˆ˜ ê³„ì‚°
        
        # ì ìˆ˜ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 10ê°œ)
        print("í‚¤ì›Œë“œ ì ìˆ˜:")
        print(pts[:10])
        print("ê³µê³ ê¸°ê´€ëª… ì ìˆ˜:")
        print(pts2[:10])
        print("ê³µì‚¬ì§€ì—­ ì ìˆ˜:")
        print(pts3[:10])
        
        # ===== ì ìˆ˜ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€ =====
        dataset_x["í‚¤ì›Œë“œì ìˆ˜"] = pts        # í‚¤ì›Œë“œ TF-IDF ì ìˆ˜ ì¶”ê°€
        dataset_x["ê³µê³ ê¸°ê´€ì ìˆ˜"] = pts2      # ê³µê³ ê¸°ê´€ëª… TF-IDF ì ìˆ˜ ì¶”ê°€
        dataset_x["ê³µì‚¬ì§€ì—­ì ìˆ˜"] = pts3      # ê³µì‚¬ì§€ì—­ TF-IDF ì ìˆ˜ ì¶”ê°€
        
        # ===== í•™ìŠµëœ ë„êµ¬ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥ =====
        self.tokenizer.save("gb.tokenizer.v0.1.1.npz")    # í˜•íƒœì†Œ ë¶„ì„ê¸° ì €ì¥
        self.vectorizer.save("gb.vectorizer.v0.1.1.npz")  # TF-IDF ë²¡í„°í™”ê¸° ì €ì¥
        
        # ===== ì¶œë ¥ ë°ì´í„°(Y) ì¤€ë¹„ =====
        # ì˜ˆì¸¡í•  ëŒ€ìƒ ë³€ìˆ˜ë“¤ (ì—…ì²´íˆ¬ì°°ë¥ , ì˜ˆê°€íˆ¬ì°°ë¥ , ì°¸ì—¬ì—…ì²´ìˆ˜)
        dataset_y = pd.DataFrame(data, columns = ['ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜'])
        dataset_y.astype({'ì—…ì²´íˆ¬ì°°ë¥ ':'float64', 'ì˜ˆê°€íˆ¬ì°°ë¥ ':'float64', 'ì°¸ì—¬ì—…ì²´ìˆ˜':'int64'})
        # ì£¼ì„ì²˜ë¦¬ëœ ì´ì „ ë²„ì „: 'íˆ¬ì°°ë¥ ì˜¤ì°¨'ë„ í¬í•¨í–ˆì—ˆìŒ
        #dataset_y.astype({'ì—…ì²´íˆ¬ì°°ë¥ ':'float64', 'ì˜ˆê°€íˆ¬ì°°ë¥ ':'float64', 'íˆ¬ì°°ë¥ ì˜¤ì°¨':'float64'})

        # ===== ì—‘ì…€ íŒŒì¼ëª… ìƒì„± =====
        # ë°ì´í„° í¬ê¸°ì™€ í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ì— ë”°ë¼ íŒŒì¼ëª… ìƒì„±
        self.excel_file_nm = self.generateExcelFileName(data_size, test_ratio)
        self.xlxs_dir = os.path.join(self.save_dir, self.excel_file_nm)
        
        print(f"ğŸ“ ìƒì„±ëœ ì—‘ì…€ íŒŒì¼ëª…: {self.excel_file_nm}")
        print(f"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {self.xlxs_dir}")
        
        # ===== í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ë¶„í•  =====
        # ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¤ì •ëœ ë¹„ìœ¨ë¡œ ë¶„í• 
        self.xx_train, self.xx_test, self.yy_train, self.yy_test = train_test_split(
                                                            dataset_x.to_numpy(),  # ì…ë ¥ ë°ì´í„° (X)
                                                            dataset_y.to_numpy(),  # ì¶œë ¥ ë°ì´í„° (Y)
                                                            test_size=test_ratio,  # ë™ì ìœ¼ë¡œ ì„¤ì •ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨
                                                            random_state=self.rnd_num  # ëœë¤ ì‹œë“œ (ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼)
                                                            )
        
        # ===== í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ =====
        # ì¸ë±ìŠ¤ [0,1,2,7,8,13,17,19,21]ì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ë“¤ë§Œ ì‚¬ìš©
        # 0:ê¸°ì´ˆê¸ˆì•¡, 1:ë‚™ì°°í•˜í•œë¥ , 2:ì°¸ì—¬ì—…ì²´ìˆ˜, 7:ê°„ì ‘ë¹„, 8:ìˆœê³µì‚¬ì›ê°€, 
        # 13:ë©´í—ˆì œí•œì½”ë“œ, 17:ê³µê³ ê¸°ê´€ì ìˆ˜, 19:ê³µì‚¬ì§€ì—­ì ìˆ˜, 21:í‚¤ì›Œë“œì ìˆ˜
        x_train = (self.arrayToDataFrame(self.xx_train, [0,1,2,7,8,13,17,19,21])).to_numpy()
        x_test = (self.arrayToDataFrame(self.xx_test, [0,1,2,7,8,13,17,19,21])).to_numpy()
        
        return x_train, x_test, self.yy_train, self.yy_test
        
    def preprocessingXset(self, x_train, x_test, scalerSaveName):
        """
        ì…ë ¥ ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            x_train (numpy.array): í›ˆë ¨ìš© ì…ë ¥ ë°ì´í„°
            x_test (numpy.array): í…ŒìŠ¤íŠ¸ìš© ì…ë ¥ ë°ì´í„°
            scalerSaveName (str): ì •ê·œí™” ë„êµ¬ë¥¼ ì €ì¥í•  íŒŒì¼ëª…
            
        Returns:
            tuple: (x_trainset, x_testset) - ì •ê·œí™”ëœ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„°
            
        ì„¤ëª…:
        - StandardScalerë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ì •ê·œí™”
        - ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ë” ì˜ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ë°ì´í„° ìŠ¤ì¼€ì¼ì„ ë§ì¶¤
        - ì •ê·œí™” ë„êµ¬ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— ì˜ˆì¸¡ ì‹œì—ë„ ë™ì¼í•˜ê²Œ ì ìš©
        """
        print("="*80)
        print("ë°ì´íƒ€ì…‹ ì •ê·œí™”ì¤‘...")
        
        # ===== ì •ê·œí™” ë„êµ¬ ì„ íƒ =====
        self.scaler = StandardScaler()  # í‘œì¤€ ì •ê·œí™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)
        # ë‹¤ë¥¸ ì •ê·œí™” ë°©ë²•ë“¤ (ì£¼ì„ì²˜ë¦¬)
        #scaler = MinMaxScaler()    # ìµœì†Œ-ìµœëŒ€ ì •ê·œí™” (0~1 ë²”ìœ„)
        #scaler = RobustScaler()    # ë¡œë²„ìŠ¤íŠ¸ ì •ê·œí™” (ì´ìƒì¹˜ì— ê°•í•¨)
        
        # ===== í›ˆë ¨ ë°ì´í„°ë¡œ ì •ê·œí™” ë„êµ¬ í•™ìŠµ =====
        x_trainset = self.scaler.fit_transform(x_train).tolist()  # í›ˆë ¨ ë°ì´í„° ì •ê·œí™”
        
        # ===== í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ê·œí™” =====
        x_testset = (self.scaler.transform(x_test)).tolist()  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ê·œí™”
        
        # ===== ì •ê·œí™” ë„êµ¬ë¥¼ íŒŒì¼ë¡œ ì €ì¥ =====
        #'gb_scaler.v2.npz'
        joblib.dump(self.scaler, self.save_dir+scalerSaveName)  # ë‚˜ì¤‘ì— ì˜ˆì¸¡ ì‹œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì €ì¥
        
        return x_trainset, x_testset
    
    def preprocessingYset(self, yy_train, yy_test):
        """
        ì¶œë ¥ ë°ì´í„°ë¥¼ 3ê°œì˜ ëª¨ë¸ìš©ìœ¼ë¡œ ë¶„ë¦¬í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            yy_train (numpy.array): í›ˆë ¨ìš© ì¶œë ¥ ë°ì´í„° [ì—…ì²´íˆ¬ì°°ë¥ , ì˜ˆê°€íˆ¬ì°°ë¥ , ì°¸ì—¬ì—…ì²´ìˆ˜]
            yy_test (numpy.array): í…ŒìŠ¤íŠ¸ìš© ì¶œë ¥ ë°ì´í„° [ì—…ì²´íˆ¬ì°°ë¥ , ì˜ˆê°€íˆ¬ì°°ë¥ , ì°¸ì—¬ì—…ì²´ìˆ˜]
            
        Returns:
            tuple: (y_trainset, y_testset) - ê°ê° 3ê°œ ëª¨ë¸ìš© ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        ì„¤ëª…:
        - ê° ëª¨ë¸ì´ ì˜ˆì¸¡í•  ëŒ€ìƒ ë³€ìˆ˜ë¥¼ ë¶„ë¦¬
        - ëª¨ë¸1: ì—…ì²´íˆ¬ì°°ë¥ , ëª¨ë¸2: ì˜ˆê°€íˆ¬ì°°ë¥ , ëª¨ë¸3: ì°¸ì—¬ì—…ì²´ìˆ˜
        """
        # ===== í›ˆë ¨ ë°ì´í„°ë¥¼ 3ê°œ ëª¨ë¸ìš©ìœ¼ë¡œ ë¶„ë¦¬ =====
        y_train1 = np.squeeze( (self.arrayToDataFrame(yy_train, [0])).to_numpy() )  # ì—…ì²´íˆ¬ì°°ë¥ 
        y_train2 = np.squeeze( (self.arrayToDataFrame(yy_train, [1])).to_numpy() )  # ì˜ˆê°€íˆ¬ì°°ë¥ 
        y_train3 = np.squeeze( (self.arrayToDataFrame(yy_train, [2])).to_numpy() )  # ì°¸ì—¬ì—…ì²´ìˆ˜
        
        # ===== í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ 3ê°œ ëª¨ë¸ìš©ìœ¼ë¡œ ë¶„ë¦¬ =====
        y_test1 = np.squeeze( (self.arrayToDataFrame(yy_test, [0])).to_numpy() )    # ì—…ì²´íˆ¬ì°°ë¥ 
        y_test2 = np.squeeze( (self.arrayToDataFrame(yy_test, [1])).to_numpy() )    # ì˜ˆê°€íˆ¬ì°°ë¥ 
        y_test3 = np.squeeze( (self.arrayToDataFrame(yy_test, [2])).to_numpy() )    # ì°¸ì—¬ì—…ì²´ìˆ˜
        
        return [y_train1, y_train2, y_train3], [y_test1, y_test2, y_test3]
        
    
    
    def setupModels(self):
        """
        3ê°œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
        
        Returns:
            list: [model1, model2, model3] - ì„¤ì •ëœ 3ê°œì˜ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
            
        ëª¨ë¸ ì„¤ëª…:
        - model1: ì—…ì²´ íˆ¬ì°°ë¥  ì˜ˆì¸¡ ëª¨ë¸ (XGBoost)
        - model2: ì˜ˆê°€ íˆ¬ì°°ë¥  ì˜ˆì¸¡ ëª¨ë¸ (LightGBM)  
        - model3: ì°¸ì—¬ ì—…ì²´ ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ (GradientBoostingRegressor)
        
        ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… íŒŒë¼ë¯¸í„° ì„¤ëª…:
        - n_estimators: ë¶€ìŠ¤íŒ… ë‹¨ê³„ ìˆ˜ (ë” ë§ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
        - max_depth: ë‚˜ë¬´ì˜ ìµœëŒ€ ê¹Šì´
        - learning_rate: í•™ìŠµë¥  (ì‘ì„ìˆ˜ë¡ ì•ˆì •ì ì´ì§€ë§Œ ëŠë¦¼)
        - subsample: ê° ë¶€ìŠ¤íŒ… ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•  ìƒ˜í”Œ ë¹„ìœ¨
        - random_state: ëœë¤ ì‹œë“œ (ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼)
        """
        print("="*80)
        print("ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ ì„¤ì • ì‹œì‘...")
        print("="*80)
        
        self.t0 = time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡

        # ===== 3ê°œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ ì„¤ì • =====
        
        # ëª¨ë¸1: ì—…ì²´ íˆ¬ì°°ë¥  ì˜ˆì¸¡ ëª¨ë¸ (XGBoost)
        if XGBOOST_AVAILABLE:
            model1 = xgb.XGBRegressor(
                                n_estimators = 200,        # ë¶€ìŠ¤íŒ… ë‹¨ê³„ 200ê°œ
                                max_depth = 6,             # ìµœëŒ€ ê¹Šì´ 6
                                learning_rate = 0.1,       # í•™ìŠµë¥  0.1
                                subsample = 0.8,           # 80% ìƒ˜í”Œ ì‚¬ìš©
                                colsample_bytree = 0.8,    # 80% íŠ¹ì„± ì‚¬ìš©
                                random_state = 1,          # ëœë¤ ì‹œë“œ
                                n_jobs = -1,               # ëª¨ë“  CPU ì‚¬ìš©
                                verbosity = 1              # ì§„í–‰ìƒí™© ì¶œë ¥
                                )
            print("âœ… XGBoost ëª¨ë¸1 ì„¤ì • ì™„ë£Œ")
        else:
            # XGBoostê°€ ì—†ìœ¼ë©´ GradientBoostingRegressor ì‚¬ìš©
            model1 = GradientBoostingRegressor(
                                n_estimators = 200,
                                max_depth = 6,
                                learning_rate = 0.1,
                                subsample = 0.8,
                                random_state = 1
                                )
            print("âš ï¸  XGBoost ì—†ìŒ - GradientBoostingRegressor ëª¨ë¸1 ì‚¬ìš©")
        
        # ëª¨ë¸2: ì˜ˆê°€ íˆ¬ì°°ë¥  ì˜ˆì¸¡ ëª¨ë¸ (LightGBM)
        if LIGHTGBM_AVAILABLE:
            model2 = lgb.LGBMRegressor(
                                n_estimators = 200,        # ë¶€ìŠ¤íŒ… ë‹¨ê³„ 200ê°œ
                                max_depth = 6,             # ìµœëŒ€ ê¹Šì´ 6
                                learning_rate = 0.1,       # í•™ìŠµë¥  0.1
                                subsample = 0.8,           # 80% ìƒ˜í”Œ ì‚¬ìš©
                                colsample_bytree = 0.8,    # 80% íŠ¹ì„± ì‚¬ìš©
                                random_state = 1,          # ëœë¤ ì‹œë“œ
                                n_jobs = -1,               # ëª¨ë“  CPU ì‚¬ìš©
                                verbosity = 1              # ì§„í–‰ìƒí™© ì¶œë ¥
                                )
            print("âœ… LightGBM ëª¨ë¸2 ì„¤ì • ì™„ë£Œ")
        else:
            # LightGBMì´ ì—†ìœ¼ë©´ GradientBoostingRegressor ì‚¬ìš©
            model2 = GradientBoostingRegressor(
                                n_estimators = 200,
                                max_depth = 6,
                                learning_rate = 0.1,
                                subsample = 0.8,
                                random_state = 1
                                )
            print("âš ï¸  LightGBM ì—†ìŒ - GradientBoostingRegressor ëª¨ë¸2 ì‚¬ìš©")
        
        # ëª¨ë¸3: ì°¸ì—¬ ì—…ì²´ ìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ (GradientBoostingRegressor)
        model3 = GradientBoostingRegressor(
                            n_estimators = 300,        # ë¶€ìŠ¤íŒ… ë‹¨ê³„ 300ê°œ (ë” ë§ìŒ)
                            max_depth = 8,             # ìµœëŒ€ ê¹Šì´ 8 (ë” ê¹ŠìŒ)
                            learning_rate = 0.05,      # í•™ìŠµë¥  0.05 (ë” ì‘ìŒ)
                            subsample = 0.9,           # 90% ìƒ˜í”Œ ì‚¬ìš©
                            random_state = 1,          # ëœë¤ ì‹œë“œ
                            verbose = 1                # ì§„í–‰ìƒí™© ì¶œë ¥
                            )
        print("âœ… GradientBoostingRegressor ëª¨ë¸3 ì„¤ì • ì™„ë£Œ")
        
        return [model1, model2, model3]
    
    def trainnng(self, model, x_trainset, y_trainset):
        """
        ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” í•¨ìˆ˜
        
        Args:
            model: í›ˆë ¨ì‹œí‚¬ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸
            x_trainset (list): í›ˆë ¨ìš© ì…ë ¥ ë°ì´í„°
            y_trainset (list): í›ˆë ¨ìš© ì¶œë ¥ ë°ì´í„°
            
        ì„¤ëª…:
        - ëª¨ë¸ì´ ì…ë ¥ ë°ì´í„°ë¥¼ ë³´ê³  ì¶œë ¥ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµ
        - ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…ì´ ìˆœì°¨ì ìœ¼ë¡œ ì˜¤ì°¨ë¥¼ ì¤„ì—¬ê°€ë©° ì˜ˆì¸¡ ì •í™•ë„ë¥¼ ë†’ì„
        """
        # í›ˆë ¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 50ê°œ)
        print("í›ˆë ¨ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        print(y_trainset[:50])
        
        # ===== ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰ =====
        model.fit(x_trainset, y_trainset)  # ëª¨ë¸ì´ ë°ì´í„°ë¥¼ í•™ìŠµ

        print("-"*80)
        print("ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ë¡œ í•™ìŠµì„ ì™„ë£Œí•˜ì˜€ìŠµë‹ˆë‹¤. ")
        
    def saveModel(self, model, filename):
        """
        í›ˆë ¨ëœ ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            model: ì €ì¥í•  ëª¨ë¸ ê°ì²´
            filename (str): ì €ì¥í•  íŒŒì¼ëª…
            
        ì„¤ëª…:
        - í›ˆë ¨ëœ ëª¨ë¸ì„ ë‚˜ì¤‘ì— ë¶ˆëŸ¬ì™€ì„œ ì˜ˆì¸¡ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì €ì¥
        - joblibì„ ì‚¬ìš©í•˜ì—¬ Python ê°ì²´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥
        """
        joblib.dump(model, self.save_dir+filename)  # ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥ (ì˜ˆ: 'gb.model1.v0.0.1.npz')
        
        print("-"*80)
        print("ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì„ ì €ì¥í•˜ì˜€ìŠµë‹ˆë‹¤. ")        
        
    def predict(self, model, x_testset):
        """
        í›ˆë ¨ëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            model: ì˜ˆì¸¡ì— ì‚¬ìš©í•  ëª¨ë¸
            x_testset (list): ì˜ˆì¸¡í•  ì…ë ¥ ë°ì´í„°
            
        Returns:
            numpy.array: ì˜ˆì¸¡ ê²°ê³¼
            
        ì„¤ëª…:
        - í›ˆë ¨ëœ ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰
        - í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•  ë•Œ ì‚¬ìš©
        """
        result = model.predict(x_testset)  # ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
        
        print("í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ì˜ˆì¸¡ì™„ë£Œ. ")
        
        return result

    def mergeResultset(self, results):
        """
        ì˜ˆì¸¡ ê²°ê³¼ë“¤ì„ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜
        
        Args:
            results (list): [ëª¨ë¸1ê²°ê³¼, ëª¨ë¸2ê²°ê³¼, ëª¨ë¸3ê²°ê³¼] ë¦¬ìŠ¤íŠ¸
            
        Returns:
            pandas.DataFrame: ì›ë³¸ ë°ì´í„°ì™€ ì˜ˆì¸¡ ê²°ê³¼ê°€ í•©ì³ì§„ ë°ì´í„°í”„ë ˆì„
        """
        df_result = self.make_result_dataframe2(self.xx_test, results[0], results[1], results[2])
        
        return df_result
        
        
    def predictByTestset(self, x_testset):
        """
        3ê°œì˜ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            x_testset (list): ì˜ˆì¸¡í•  í…ŒìŠ¤íŠ¸ ë°ì´í„°
            
        Returns:
            pandas.DataFrame: ì˜ˆì¸¡ ê²°ê³¼ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
            
        ì„¤ëª…:
        - 3ê°œì˜ ëª¨ë¸ì„ ëª¨ë‘ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
        - ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ë°˜í™˜
        """
        # 3ê°œì˜ ëª¨ë¸ë¡œ ê°ê° ì˜ˆì¸¡ ìˆ˜í–‰
        result1 = self.model1.predict(x_testset)  # ì—…ì²´ íˆ¬ì°°ë¥  ì˜ˆì¸¡
        result2 = self.model2.predict(x_testset)  # ì˜ˆê°€ íˆ¬ì°°ë¥  ì˜ˆì¸¡
        result3 = self.model3.predict(x_testset)  # ì°¸ì—¬ ì—…ì²´ ìˆ˜ ì˜ˆì¸¡
        
        print("í…ŒìŠ¤íŠ¸ì…‹ìœ¼ë¡œ ì˜ˆì¸¡ì™„ë£Œ. ")
        
        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬
        df_result = self.make_result_dataframe2(self.xx_test, result1, result2, result3)
        
        return df_result
    
    
    def saveResultToXls(self, df_result, xls_dir):
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            df_result (pandas.DataFrame): ì €ì¥í•  ë°ì´í„°í”„ë ˆì„
            xls_dir (str): ì €ì¥í•  ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
            
        ì„¤ëª…:
        - ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ í•¨
        - openpyxlì´ ì—†ìœ¼ë©´ CSV íŒŒì¼ë¡œ ì €ì¥
        - ê²°ê³¼1, ê²°ê³¼2 í†µê³„ë¥¼ ë§ˆì§€ë§‰ì— ì¶”ê°€
        """
        print("="*80)
        print("ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")
        print(f"ì €ì¥ ê²½ë¡œ: {xls_dir}")
        print(f"ë°ì´í„° í–‰ ìˆ˜: {len(df_result)}")
        print(f"ë°ì´í„° ì—´ ìˆ˜: {len(df_result.columns)}")
        
        try:
            # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ ì‹œë„
            df_result.to_excel(
                           xls_dir,  # ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
                           sheet_name = 'Sheet1',        # ì‹œíŠ¸ ì´ë¦„
                           na_rep = 'NaN',               # ê²°ì¸¡ê°’ í‘œì‹œ
                           float_format = "%.8f",        # ì†Œìˆ˜ì  8ìë¦¬ê¹Œì§€ í‘œì‹œ
                           header = True,                # ì»¬ëŸ¼ëª… í¬í•¨
                           index = True,                 # ì¸ë±ìŠ¤ í¬í•¨
                           index_label = "id",           # ì¸ë±ìŠ¤ ì»¬ëŸ¼ëª…
                           startrow = 1,                 # ì‹œì‘ í–‰
                           startcol = 1,                 # ì‹œì‘ ì—´
                           freeze_panes = (2, 0)         # ì²« 2í–‰ ê³ ì • (ìŠ¤í¬ë¡¤ ì‹œì—ë„ ì»¬ëŸ¼ëª… ìœ ì§€)
                           )
            
            # ===== ê²°ê³¼1, ê²°ê³¼2 í†µê³„ ì¶”ê°€ =====
            self.addResultStatistics(xls_dir, df_result)
            
            print("="*80)
            print("âœ… ì˜ˆì¸¡ë°ì´íƒ€ë¥¼ ì—‘ì…€íŒŒì¼ë¡œ ì €ì¥í•˜ì˜€ìŠµë‹ˆë‹¤.")
            print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼: {xls_dir}")
            print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(df_result)}í–‰ x {len(df_result.columns)}ì—´")
            print("ğŸ“ˆ ê²°ê³¼1, ê²°ê³¼2 í†µê³„ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print("="*80)
        except ModuleNotFoundError:
            # openpyxlì´ ì—†ìœ¼ë©´ CSV íŒŒì¼ë¡œ ì €ì¥
            csv_dir = xls_dir.replace('.xlsx', '.csv')
            df_result.to_csv(csv_dir, 
                           na_rep = 'NaN', 
                           float_format = "%.8f", 
                           header = True, 
                           index = True, 
                           index_label = "id",
                           encoding='utf-8-sig')
            print("="*80)
            print("âš ï¸  openpyxlì´ ì—†ì–´ì„œ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ì˜€ìŠµë‹ˆë‹¤.")
            print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼: {csv_dir}")
            print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(df_result)}í–‰ x {len(df_result.columns)}ì—´")
            print("="*80)
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨ìœ¼ë¡œ CSV íŒŒì¼ë¡œ ì €ì¥
            csv_dir = xls_dir.replace('.xlsx', '.csv')
            df_result.to_csv(csv_dir, 
                           na_rep = 'NaN', 
                           float_format = "%.8f", 
                           header = True, 
                           index = True, 
                           index_label = "id",
                           encoding='utf-8-sig')
            print("="*80)
            print("âœ… CSV íŒŒì¼ë¡œ ì €ì¥í•˜ì˜€ìŠµë‹ˆë‹¤.")
            print(f"ğŸ“ ì €ì¥ëœ íŒŒì¼: {csv_dir}")
            print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(df_result)}í–‰ x {len(df_result.columns)}ì—´")
            print("="*80)
    
    def addResultStatistics(self, xls_dir, df_result):
        """
        ì—‘ì…€ íŒŒì¼ì— ê²°ê³¼1, ê²°ê³¼2 í†µê³„ë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            xls_dir (str): ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
            df_result (pandas.DataFrame): ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
            
        ì„¤ëª…:
        - ê²°ê³¼1 ì»¬ëŸ¼(AD)ì˜ "ë‚™ì°°" ê°œìˆ˜ì™€ ë¹„ìœ¨ ê³„ì‚°
        - ê²°ê³¼2 ì»¬ëŸ¼(AG)ì˜ "ë‚™ì°°" ê°œìˆ˜ì™€ ë¹„ìœ¨ ê³„ì‚°
        - ì—‘ì…€ íŒŒì¼ ë§ˆì§€ë§‰ì— í†µê³„ ì¶”ê°€
        """
        try:
            if not OPENPYXL_AVAILABLE:
                raise ImportError("openpyxlì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ì—‘ì…€ íŒŒì¼ ë¡œë“œ
            wb = load_workbook(xls_dir)
            ws = wb.active
            
            # ë°ì´í„° í–‰ ìˆ˜ ê³„ì‚° (í—¤ë” ì œì™¸)
            data_rows = len(df_result)
            start_row = 3  # ë°ì´í„° ì‹œì‘ í–‰ (í—¤ë” 2í–‰ + 1)
            end_row = start_row + data_rows - 1
            
            # ===== ê²°ê³¼1 í†µê³„ ì¶”ê°€ =====
            # ê²°ê³¼1 ë‚™ì°° ê°œìˆ˜ (AD ì»¬ëŸ¼) - Aê°’ì—¬ë¶€ì™€ ê°™ì€ ì—´(AC)ì— ë°°ì¹˜
            stats_row = end_row + 2
            ws[f'AC{stats_row}'] = "=== ê²°ê³¼1 í†µê³„ ==="
            ws[f'AC{stats_row}'].font = openpyxl.styles.Font(bold=True, color="0000FF")
            
            # ê²°ê³¼1 ë‚™ì°° ê°œìˆ˜ - ë” ì•ˆì „í•œ ê³µì‹ ì‚¬ìš©
            ws[f'AC{stats_row + 1}'] = "ë‚™ì°° ê°œìˆ˜:"
            count_formula1 = f'=COUNTIF(AD{start_row}:AD{end_row},"ë‚™ì°°")'
            ws[f'AD{stats_row + 1}'] = count_formula1
            
            # ê²°ê³¼1 ë‚™ì°° ë¹„ìœ¨ - ë” ì•ˆì „í•œ ê³µì‹ ì‚¬ìš©
            ws[f'AC{stats_row + 2}'] = "ë‚™ì°° ë¹„ìœ¨:"
            rate_formula1 = f'=IF(AD{stats_row + 1}>0,AD{stats_row + 1}/{data_rows}*100,0)'
            ws[f'AD{stats_row + 2}'] = rate_formula1
            
            # ===== ê²°ê³¼2 í†µê³„ ì¶”ê°€ =====
            # ê²°ê³¼2 ë‚™ì°° ê°œìˆ˜ (AG ì»¬ëŸ¼) - ê²°ê³¼1ê³¼ ë™ì¼í•œ í–‰ì— ë°°ì¹˜ (AF ì»¬ëŸ¼ì— ì„¤ëª…)
            ws[f'AF{stats_row}'] = "=== ê²°ê³¼2 í†µê³„ ==="
            ws[f'AF{stats_row}'].font = openpyxl.styles.Font(bold=True, color="00AA00")
            
            # ê²°ê³¼2 ë‚™ì°° ê°œìˆ˜ - ë” ì•ˆì „í•œ ê³µì‹ ì‚¬ìš©
            ws[f'AF{stats_row + 1}'] = "ë‚™ì°° ê°œìˆ˜:"
            count_formula2 = f'=COUNTIF(AG{start_row}:AG{end_row},"ë‚™ì°°")'
            ws[f'AG{stats_row + 1}'] = count_formula2
            
            # ê²°ê³¼2 ë‚™ì°° ë¹„ìœ¨ - ë” ì•ˆì „í•œ ê³µì‹ ì‚¬ìš©
            ws[f'AF{stats_row + 2}'] = "ë‚™ì°° ë¹„ìœ¨:"
            rate_formula2 = f'=IF(AG{stats_row + 1}>0,AG{stats_row + 1}/{data_rows}*100,0)'
            ws[f'AG{stats_row + 2}'] = rate_formula2
            
            # ===== ì¶”ê°€ ì •ë³´ =====
            ws[f'A{stats_row + 4}'] = "=== ìš”ì•½ ì •ë³´ ==="
            ws[f'A{stats_row + 4}'].font = openpyxl.styles.Font(bold=True, color="FF0000")
            ws[f'A{stats_row + 5}'] = f"ì´ ë°ì´í„° ê°œìˆ˜: {data_rows}ê°œ"
            ws[f'A{stats_row + 6}'] = f"ë°ì´í„° ë²”ìœ„: AD{start_row}:AD{end_row}, AG{start_row}:AG{end_row}"
            
            # ì—‘ì…€ íŒŒì¼ ì €ì¥
            wb.save(xls_dir)
            
            print(f"ğŸ“Š ê²°ê³¼1 í†µê³„ ì¶”ê°€ ì™„ë£Œ:")
            print(f"   - ë‚™ì°° ê°œìˆ˜: AD{stats_row + 1} = {count_formula1}")
            print(f"   - ë‚™ì°° ë¹„ìœ¨: AD{stats_row + 2} = {rate_formula1}")
            print(f"ğŸ“Š ê²°ê³¼2 í†µê³„ ì¶”ê°€ ì™„ë£Œ:")
            print(f"   - ë‚™ì°° ê°œìˆ˜: AG{stats_row + 1} = {count_formula2}")
            print(f"   - ë‚™ì°° ë¹„ìœ¨: AG{stats_row + 2} = {rate_formula2}")
            print(f"ğŸ“Š í†µê³„ ìœ„ì¹˜: {stats_row}í–‰ (ë°ì´í„° ë§ˆì§€ë§‰ + 2í–‰)")
            
        except ImportError:
            print("âš ï¸  openpyxlì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ í†µê³„ë¥¼ ì¶”ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   pip install openpyxl ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        except Exception as e:
            print(f"âŒ í†µê³„ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(f"   ì˜¤ë¥˜ ìƒì„¸: {str(e)}") 
        
    
    def close(self):
        """
        í›ˆë ¨ ê³¼ì •ì„ ë§ˆë¬´ë¦¬í•˜ëŠ” í•¨ìˆ˜
        
        ì„¤ëª…:
        - ì „ì²´ í›ˆë ¨ ê³¼ì •ì— ê±¸ë¦° ì‹œê°„ì„ ê³„ì‚°í•˜ì—¬ ì¶œë ¥
        - í›ˆë ¨ ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥
        """
        print("-"*80)
        
        # ì „ì²´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚° ë° ì¶œë ¥
        print(f"â±ï¸  ì „ì²´ ì‹¤í–‰ ì‹œê°„: {time() - self.t0:.3f}ì´ˆ")
        
        print("="*80)
        print("ğŸ‰ ë¨¸ì‹ ëŸ¬ë‹ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!")
        if self.excel_file_nm:
            print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {self.excel_file_nm}")
            print(f"ğŸ“‚ ì €ì¥ ìœ„ì¹˜: {self.save_dir}")
        else:
            print("âš ï¸  ì—‘ì…€ íŒŒì¼ëª…ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("="*80)

        



def Main():
    """
    ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ì˜ ì „ì²´ ê³¼ì •ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    
    ì‹¤í–‰ ê³¼ì •:
    1. í›ˆë ¨ ê°ì²´ ìƒì„±
    2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    3. 3ê°œ ëª¨ë¸ ì„¤ì •
    4. ê° ëª¨ë¸ í›ˆë ¨ ë° ì €ì¥
    5. ì˜ˆì¸¡ ìˆ˜í–‰ ë° ê²°ê³¼ ì €ì¥
    6. ì—‘ì…€ íŒŒì¼ë¡œ ê²°ê³¼ ì¶œë ¥
    """
    # ===== 1ë‹¨ê³„: í›ˆë ¨ ê°ì²´ ìƒì„± =====
    trainer = BidLowerMarginRateTrain()
    
    # ===== 2ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ =====
    x_train, x_test, y_train, y_test = trainer.loadTrainsetFromFile('bid_250921_30.csv')  # CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
    x_trainset, x_testset = trainer.preprocessingXset(x_train, x_test, 'gb_scaler.v2.npz')  # ì…ë ¥ ë°ì´í„° ì •ê·œí™”
    y_trainset, y_testset = trainer.preprocessingYset(y_train, y_test)  # ì¶œë ¥ ë°ì´í„° ë¶„ë¦¬
    
    # ===== 3ë‹¨ê³„: 3ê°œ ëª¨ë¸ ì„¤ì • =====
    models = trainer.setupModels()  # [ì—…ì²´íˆ¬ì°°ë¥ ëª¨ë¸, ì˜ˆê°€íˆ¬ì°°ë¥ ëª¨ë¸, ì°¸ì—¬ì—…ì²´ìˆ˜ëª¨ë¸]
    results = []  # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    
    # ===== 4ë‹¨ê³„: ê° ëª¨ë¸ í›ˆë ¨ ë° ì €ì¥ =====
    for i, model in enumerate(models):
        trainer.trainnng(model, x_trainset, y_trainset[i])  # ëª¨ë¸ í›ˆë ¨
        trainer.saveModel(model, f'gb.model{i+1}.v0.1.1.npz')  # ëª¨ë¸ ì €ì¥
        result = trainer.predict(model, x_testset)  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì˜ˆì¸¡
        print(f"ëª¨ë¸{i+1} ì˜ˆì¸¡ ê²°ê³¼ (ì²˜ìŒ 50ê°œ):")
        print(result[:50])
        print("="*80)
        results.append(result)  # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
        
    # ===== 5ë‹¨ê³„: ê²°ê³¼ ì •ë¦¬ ë° ì €ì¥ =====
    print("="*80)
    print("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬ ì¤‘...")
    df_result = trainer.mergeResultset(results)  # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì •ë¦¬
    print(f"âœ… ë°ì´í„°í”„ë ˆì„ ìƒì„± ì™„ë£Œ: {len(df_result)}í–‰ x {len(df_result.columns)}ì—´")
    
    print("="*80)
    print("ğŸ’¾ ì—‘ì…€ íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥ ì¤‘...")
    trainer.saveResultToXls(df_result, trainer.xlxs_dir)  # ì—‘ì…€ íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥
    
    trainer.close()  # í›ˆë ¨ ê³¼ì • ë§ˆë¬´ë¦¬

    
if __name__ == "__main__":
    """
    ìŠ¤í¬ë¦½íŠ¸ê°€ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ Main() í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
    
    ì„¤ëª…:
    - ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œë§Œ ë¨¸ì‹ ëŸ¬ë‹ í›ˆë ¨ì´ ì‹œì‘ë¨
    - ë‹¤ë¥¸ íŒŒì¼ì—ì„œ importí•  ë•ŒëŠ” ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
    """
    Main()