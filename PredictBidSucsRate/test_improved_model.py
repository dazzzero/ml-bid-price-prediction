# -*- coding: utf-8 -*-
"""
ê°œì„ ëœ ë°ì´í„°ë¡œ í•™ìŠµí•œ ëª¨ë¸ì˜ ì‹¤ì œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
bid.ml.train.pyì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì—‘ì…€ë¡œ ìƒì„±

@author: user
"""

import os
import joblib
import numpy as np
import pandas as pd
from time import time
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

# ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import openpyxl
    from openpyxl import load_workbook
    OPENPYXL_AVAILABLE = True
except ImportError:
    OPENPYXL_AVAILABLE = False
    print("âš ï¸  openpyxlì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì—‘ì…€ í†µê³„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install openpyxl'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from kiwipiepy import Kiwi
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import csr_matrix

# ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
from advanced_feature_engineering import AdvancedFeatureEngineering

class KiwiTokenizer():
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, saved_filenm):
        self.rnd_num = np.random.randint(100, 999)
        self.cur_dir = os.getcwd()
        self.data_dir = self.cur_dir+'\\data\\'
        self.save_dir = self.cur_dir+'\\res\\'
        self.save_filename = saved_filenm
        self.kiwi = None
        self.kiwi = self.CreateKiwi(saved_filenm)
    
    def save(self, filename):
        joblib.dump(self.kiwi._user_values, self.save_dir+filename)
        return self
    
    def load(self, filename):
        o = joblib.load(filename)
        return o
        
    def loadDictonary(self, filename):
        self.data = pd.read_csv(self.data_dir+filename)
        for i, row in enumerate(self.data.iloc):
            self.kiwi.add_user_word(row["ë‹¨ì–´"], 'NNP')
    
    def CreateKiwi(self, saved_filenm):
        o = None
        if(self.kiwi is None):
            if(saved_filenm is None):
                o = Kiwi(num_workers=8)
            else:
                o = Kiwi(num_workers=8)
                o._user_values = self.load(saved_filenm)
        return o
            
    def cleared_line(self, line):
        if pd.isna(line) or line is None:
            line = ''
        else:
            line = str(line).lower().replace('(', ' ').replace(')', ' ').replace('n/a', '')
        
        nm_words = []
        tokens = self.kiwi.tokenize(line)
        for token in tokens:
            if token.tag in ['MM', 'NNG', 'NNB', 'NNP', 'SL', 'XPN', 'MAG', 'SN', 'SO', 'W_SERIAL']:
                nm_words.append(token.form)
                
        return ' '.join(nm_words)
    
    def cleared_lines_from(self, orglines):
        lines = []
        for line in orglines:
            lines.append(self.cleared_line(line))
        return lines      
    
    def nn_only(self, orglines):
        lines = []
        for key in orglines:
            if pd.isna(key) or key is None:
                key = ''
            else:
                key = str(key).lower().replace('(', ' ').replace(')', ' ').replace('n/a', '')
            
            nm_words = []
            tokens = self.kiwi.tokenize(key)
            for token in tokens:
                if token.tag in ['MM', 'NNG', 'NNB', 'NNP', 'SL', 'XPN', 'MAG', 'SN', 'SO', 'W_SERIAL']:
                    nm_words.append(token.form)
            lines.append(' '.join(nm_words))
            
        return lines

class KiwiVectorizer():
    def __init__(self):
        self.rnd_num = np.random.randint(100, 999)
        self.cur_dir = os.getcwd()
        self.save_dir = self.cur_dir+'\\res\\'
        
        self.vect = TfidfVectorizer(
            ngram_range=(1, 1), 
            token_pattern='(?u)\\b\\w+\\b',
            max_features=5000,
            min_df=2,
            max_df=0.95,
            sublinear_tf=True
        )
    
    def load(self, filename):
        voca = joblib.load(filename)
        self.vect.vocabulary_ = voca["vocabulary"] 
        self.vect.idf_ = voca["idf"]
    
    def save(self, filename):
        joblib.dump({'vocabulary':self.vect.vocabulary_, 'idf':self.vect.idf_}, self.save_dir + filename)
        print("ë‹¨ì–´ì‚¬ì „ íŒŒì¼("+filename+")ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ")
    
    def fit(self, lines):
        return self.vect.fit(lines)
    
    def transform(self, lines):
        return self.vect.transform(lines)
    
    def scores(self, lines):
        return self.toValues(self.transform(lines))

    def toValues(self, csrmat:csr_matrix):
        lst = []
        safty_sz = len(csrmat.indptr)-1
        for i, n in enumerate(csrmat.indptr):
            sumval = 0
            if i<safty_sz:
                indiceVal = csrmat.indices[csrmat.indptr[i]:csrmat.indptr[i+1]]
                dataVal = csrmat.data[csrmat.indptr[i]:csrmat.indptr[i+1]]
                for j, va1 in enumerate(indiceVal):
                    sumval += va1 * dataVal[j]
                lst.append(sumval)
        return lst

class ImprovedModelTester():
    """ê°œì„ ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.cur_dir = os.getcwd()
        self.data_dir = self.cur_dir+'\\data\\'
        self.save_dir = self.cur_dir+'\\res\\'
        
        # ê²°ê³¼ ì»¬ëŸ¼ ì •ì˜ (bid.ml.train.pyì™€ ë™ì¼)
        self.result_columns = ['ì…ì°°ë²ˆí˜¸', 'ì…ì°°ì°¨ìˆ˜', 'ê¸°ì´ˆê¸ˆì•¡', 
                               'ë‚™ì°°í•˜í•œë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜', 'ê°„ì ‘ë¹„', 'ìˆœê³µì‚¬ì›ê°€', 
                               'ë©´í—ˆì œí•œì½”ë“œ', 'ê³µê³ ê¸°ê´€ì½”ë“œ',
                               'ê³µê³ ê¸°ê´€ëª…', 'ê³µê³ ê¸°ê´€ì ìˆ˜',
                               'ê³µì‚¬ì§€ì—­', 'ê³µì‚¬ì§€ì—­ì ìˆ˜',                               
                               'í‚¤ì›Œë“œ', 'í‚¤ì›Œë“œì ìˆ˜',
                               'ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'íˆ¬ì°°ë¥ ì˜¤ì°¨', 
                               'ì˜ˆì •ê¸ˆì•¡', 'ë‚™ì°°í•˜í•œê°€', 'ë‚™ì°°ê¸ˆì•¡', 
                               'ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡', 'ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡', 'ì°¸ì—¬ì—…ì²´ìˆ˜ì˜ˆì¸¡', 'ì˜ˆì •ê¸ˆì•¡ì˜ˆì¸¡',
                               'ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡', 'Aê°’ì—¬ë¶€', 'ê²°ê³¼1', 
                               'ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡', 'ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨', 'ê²°ê³¼2']
        
        # ê²°ê³¼ ì»¬ëŸ¼ íƒ€ì… ì •ì˜
        self.result_columns_type = {
                            'ì…ì°°ë²ˆí˜¸':'str', 'ì…ì°°ì°¨ìˆ˜':'int64','ê¸°ì´ˆê¸ˆì•¡':'float64',
                            'ë‚™ì°°í•˜í•œë¥ ':'float64', 'ì°¸ì—¬ì—…ì²´ìˆ˜':'float64', 'ê°„ì ‘ë¹„':'int64', 'ìˆœê³µì‚¬ì›ê°€':'int64',  
                            'ë©´í—ˆì œí•œì½”ë“œ':'float64', 'ê³µê³ ê¸°ê´€ì½”ë“œ':'float64',
                            'ê³µê³ ê¸°ê´€ëª…':'str', 'ê³µê³ ê¸°ê´€ì ìˆ˜':'float64',
                            'ê³µì‚¬ì§€ì—­':'str', 'ê³µì‚¬ì§€ì—­ì ìˆ˜':'float64',                            
                            'í‚¤ì›Œë“œ':'str', 'í‚¤ì›Œë“œì ìˆ˜':'float64',
                            'ì—…ì²´íˆ¬ì°°ë¥ ':'float64', 'ì˜ˆê°€íˆ¬ì°°ë¥ ':'float64', 'íˆ¬ì°°ë¥ ì˜¤ì°¨':'float64', 
                            'ì˜ˆì •ê¸ˆì•¡':'int64', 'ë‚™ì°°í•˜í•œê°€':'int64', 'ë‚™ì°°ê¸ˆì•¡':'int64', 
                            'ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡':'float64', 'ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡':'float64', 'ì°¸ì—¬ì—…ì²´ìˆ˜ì˜ˆì¸¡':'float64', 'ì˜ˆì •ê¸ˆì•¡ì˜ˆì¸¡':'int64',
                            'ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡':'float64', 'Aê°’ì—¬ë¶€':'str', 'ê²°ê³¼1':'str',
                            'ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡':'float64', 'ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨':'float64', 'ê²°ê³¼2':'str'
                            }
        
        # í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë„êµ¬ë“¤ ì´ˆê¸°í™”
        self.tokenizer = KiwiTokenizer(self.save_dir + "mlpregr.tokenizer.v0.1.1.npz")
        self.vectorizer = KiwiVectorizer()
        self.vectorizer.load(self.save_dir + "mlpregr.vectorizer.v0.1.1.npz")
        
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        self.scaler = joblib.load(self.save_dir + 'x_fited_scaler.v2.npz')
        
        # ëª¨ë¸ë“¤ ë¡œë“œ
        self.model1 = joblib.load(self.save_dir + 'mlpregr.model1.v0.1.1.npz')
        self.model2 = joblib.load(self.save_dir + 'mlpregr.model2.v0.1.1.npz')
        self.model3 = joblib.load(self.save_dir + 'mlpregr.model3.v0.1.1.npz')
        
        print("âœ… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ë„êµ¬ ë¡œë“œ ì™„ë£Œ")

    def load_test_data(self, filename):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ: {filename}")
        
        # ë°ì´í„° ë¡œë“œ
        data = pd.read_csv(self.data_dir + filename, encoding='utf-8')
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {data.shape[0]}í–‰, {data.shape[1]}ì—´")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë“¤ë§Œ ì„ íƒ
        cvs_columns = ['ê¸°ì´ˆê¸ˆì•¡', 'ë‚™ì°°í•˜í•œë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜', 
                      'ë‚™ì°°ê¸ˆì•¡', 'ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'íˆ¬ì°°ë¥ ì˜¤ì°¨', 
                      'ê°„ì ‘ë¹„', 'ìˆœê³µì‚¬ì›ê°€', 'ì…ì°°ë²ˆí˜¸', 'ì…ì°°ì°¨ìˆ˜', 
                      'ì˜ˆì •ê¸ˆì•¡', 'ë‚™ì°°í•˜í•œê°€', 
                      'ë©´í—ˆì œí•œì½”ë“œ','ê³µê³ ê¸°ê´€ì½”ë“œ','ì£¼ê³µì¢…ëª…', 
                      'ê³µê³ ê¸°ê´€ëª…', 'ê³µê³ ê¸°ê´€ì ìˆ˜',
                      'ê³µì‚¬ì§€ì—­', 'ê³µì‚¬ì§€ì—­ì ìˆ˜',
                      'í‚¤ì›Œë“œ', 'í‚¤ì›Œë“œì ìˆ˜']
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_columns = [col for col in cvs_columns if col in data.columns]
        dataset_x = pd.DataFrame(data, columns=available_columns)
        
        # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì²˜ë¦¬
        print("ğŸ”§ í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        if 'í‚¤ì›Œë“œ' in dataset_x.columns:
            dataset_x['í‚¤ì›Œë“œ'] = dataset_x['í‚¤ì›Œë“œ'].fillna('').astype(str)
        if 'ê³µê³ ê¸°ê´€ëª…' in dataset_x.columns:
            dataset_x['ê³µê³ ê¸°ê´€ëª…'] = dataset_x['ê³µê³ ê¸°ê´€ëª…'].fillna('').astype(str)
        if 'ê³µì‚¬ì§€ì—­' in dataset_x.columns:
            dataset_x['ê³µì‚¬ì§€ì—­'] = dataset_x['ê³µì‚¬ì§€ì—­'].fillna('').astype(str)
        
        # ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜
        if 'ë©´í—ˆì œí•œì½”ë“œ' in dataset_x.columns:
            dataset_x['ë©´í—ˆì œí•œì½”ë“œ'] = dataset_x['ë©´í—ˆì œí•œì½”ë“œ'].astype(str).apply(
                lambda x: hash(x) % 1000000 if pd.notna(x) and x != 'nan' else 0)
        if 'ê³µê³ ê¸°ê´€ì½”ë“œ' in dataset_x.columns:
            dataset_x['ê³µê³ ê¸°ê´€ì½”ë“œ'] = dataset_x['ê³µê³ ê¸°ê´€ì½”ë“œ'].astype(str).apply(
                lambda x: hash(x) % 1000000 if pd.notna(x) and x != 'nan' else 0)
        
        # í…ìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬
        lines = self.tokenizer.nn_only(dataset_x["í‚¤ì›Œë“œ"].tolist())
        lines2 = self.tokenizer.nn_only(dataset_x["ê³µê³ ê¸°ê´€ëª…"].tolist())
        lines3 = self.tokenizer.nn_only(dataset_x["ê³µì‚¬ì§€ì—­"].tolist())
        
        # TF-IDF ì ìˆ˜ ê³„ì‚°
        pts = self.vectorizer.scores(lines)
        pts2 = self.vectorizer.scores(lines2)
        pts3 = self.vectorizer.scores(lines3)
        
        # ì ìˆ˜ë¥¼ ë°ì´í„°ì— ì¶”ê°€
        dataset_x["í‚¤ì›Œë“œì ìˆ˜"] = pts
        dataset_x["ê³µê³ ê¸°ê´€ì ìˆ˜"] = pts2
        dataset_x["ê³µì‚¬ì§€ì—­ì ìˆ˜"] = pts3
        
        # ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì ìš©
        print("ğŸ”§ ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì ìš© ì¤‘...")
        feature_eng = AdvancedFeatureEngineering()
        
        dataset_x = feature_eng.create_interaction_features(dataset_x)
        dataset_x = feature_eng.create_ratio_features(dataset_x)
        dataset_x = feature_eng.create_categorical_features(dataset_x)
        dataset_x = feature_eng.create_statistical_features(dataset_x)
        
        print(f"âœ… íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ: {dataset_x.shape[1]}ê°œ íŠ¹ì„±")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ì¤€ë¹„
        dataset_y = pd.DataFrame(data, columns=['ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜'])
        
        return dataset_x, dataset_y, data

    def make_result_dataframe(self, xx_test, result1, result2, result3, original_data):
        """ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„± (bid.ml.train.pyì™€ ë™ì¼)"""
        df_rst = pd.DataFrame(columns=self.result_columns)
        df_rst.astype(self.result_columns_type)
        
        selected_cols = ['ì…ì°°ë²ˆí˜¸', 'ì…ì°°ì°¨ìˆ˜', 
                         'ê¸°ì´ˆê¸ˆì•¡', 'ë‚™ì°°í•˜í•œë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜', 'ê°„ì ‘ë¹„', 'ìˆœê³µì‚¬ì›ê°€', 
                         'ë©´í—ˆì œí•œì½”ë“œ', 'ê³µê³ ê¸°ê´€ì½”ë“œ', 
                         'í‚¤ì›Œë“œ', 'í‚¤ì›Œë“œì ìˆ˜', 
                         'ê³µê³ ê¸°ê´€ëª…', 'ê³µê³ ê¸°ê´€ì ìˆ˜',
                         'ê³µì‚¬ì§€ì—­', 'ê³µì‚¬ì§€ì—­ì ìˆ˜',                             
                         'ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'íˆ¬ì°°ë¥ ì˜¤ì°¨', 
                         'ì˜ˆì •ê¸ˆì•¡', 'ë‚™ì°°í•˜í•œê°€', 'ë‚™ì°°ê¸ˆì•¡']
        
        # ì›ë³¸ ë°ì´í„°ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë“¤ ì„ íƒ
        df_test = original_data[selected_cols].copy()
        
        print("ì˜ˆì¸¡ê²°ê³¼ê°’ ì…ë ¥ ì‹œì‘")
        
        for i, v in enumerate(selected_cols):
            if v in df_test.columns:
                df_rst[v] = df_test[v]
                
        df_rst["ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡"] = result1
        df_rst["ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡"] = result2
        df_rst["ì°¸ì—¬ì—…ì²´ìˆ˜ì˜ˆì¸¡"] = result3
        
        # ì˜ˆê°€íˆ¬ì°°ë¥  ì˜ˆì¸¡ê°’ìœ¼ë¡œë¶€í„° ì˜ˆì •ê¸ˆì•¡ ì—­ì‚° ê³„ì‚°
        df_rst["ì˜ˆì •ê¸ˆì•¡ì˜ˆì¸¡"] = (df_rst["ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡"] * df_rst["ê¸°ì´ˆê¸ˆì•¡"]) / df_rst["ë‚™ì°°í•˜í•œë¥ "]
        
        # ìƒˆë¡œìš´ ì»¬ëŸ¼ë“¤ ê³„ì‚°
        df_rst["ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡"] = df_rst["ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡"] * df_rst["ê¸°ì´ˆê¸ˆì•¡"]
        df_rst["Aê°’ì—¬ë¶€"] = df_rst["ì—…ì²´íˆ¬ì°°ë¥ ì˜ˆì¸¡"].apply(lambda x: 'O' if x >= 0.8 else '')
        
        # ê²°ê³¼1 ê³„ì‚°
        def calculate_result1(row):
            predicted_amount = row["ë‚™ì°°ê¸ˆì•¡(ì—…ì²´íˆ¬ì°°ë¥ ) ì˜ˆì¸¡"]
            min_bid = row["ë‚™ì°°í•˜í•œê°€"]
            actual_amount = row["ë‚™ì°°ê¸ˆì•¡"]
            
            if predicted_amount < min_bid:
                return "ë‚™ì°°í•˜í•œì„ ë¯¸ë‹¬"
            elif predicted_amount >= min_bid and predicted_amount < actual_amount:
                return "ë‚™ì°°"
            else:
                return "-"
        
        df_rst["ê²°ê³¼1"] = df_rst.apply(calculate_result1, axis=1)
        
        # ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡
        df_rst["ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡"] = (df_rst["ì˜ˆê°€íˆ¬ì°°ë¥ ì˜ˆì¸¡"] / df_rst["ë‚™ì°°í•˜í•œë¥ "]) * df_rst["ê¸°ì´ˆê¸ˆì•¡"]
        df_rst["ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨"] = df_rst["ì˜ˆì •ê¸ˆì•¡(ì˜ˆê°€íˆ¬ì°°ë¥ ) ì˜ˆì¸¡"] * df_rst["ë‚™ì°°í•˜í•œë¥ "]
        
        # ê²°ê³¼2 ê³„ì‚°
        def calculate_result2(row):
            predicted_amount = row["ì˜ˆì •ê¸ˆì•¡*ë‚™ì°°í•˜í•œìœ¨"]
            min_bid = row["ë‚™ì°°í•˜í•œê°€"]
            actual_amount = row["ë‚™ì°°ê¸ˆì•¡"]
            
            if predicted_amount < min_bid:
                return "ë‚™ì°°í•˜í•œì„ ë¯¸ë‹¬"
            elif predicted_amount >= min_bid and predicted_amount < actual_amount:
                return "ë‚™ì°°"
            else:
                return "-"
        
        df_rst["ê²°ê³¼2"] = df_rst.apply(calculate_result2, axis=1)
        
        print("ì˜ˆì¸¡ê²°ê³¼í…Œì´ë¸” ì‘ì„±ì™„ë£Œ")
        return df_rst

    def predict_and_evaluate(self, dataset_x, dataset_y):
        """ì˜ˆì¸¡ ìˆ˜í–‰ ë° ì„±ëŠ¥ í‰ê°€"""
        print("ğŸ¤– ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
        
        # ì›ë³¸ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ íŠ¹ì„±ë“¤ë§Œ ì„ íƒ (bid.ml.train.pyì™€ ë™ì¼)
        # ì¸ë±ìŠ¤ [0,1,2,7,8,13,17,19,21]ì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ë“¤ë§Œ ì‚¬ìš©
        original_features = ['ê¸°ì´ˆê¸ˆì•¡', 'ë‚™ì°°í•˜í•œë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜', 'ê°„ì ‘ë¹„', 'ìˆœê³µì‚¬ì›ê°€', 
                           'ë©´í—ˆì œí•œì½”ë“œ', 'ê³µê³ ê¸°ê´€ì ìˆ˜', 'ê³µì‚¬ì§€ì—­ì ìˆ˜', 'í‚¤ì›Œë“œì ìˆ˜']
        
        # ì¡´ì¬í•˜ëŠ” íŠ¹ì„±ë§Œ ì„ íƒ
        available_features = [col for col in original_features if col in dataset_x.columns]
        X_selected = dataset_x[available_features].fillna(0)
        
        print(f"ğŸ“Š ì‚¬ìš©í•  íŠ¹ì„± ìˆ˜: {len(available_features)}ê°œ")
        print(f"ğŸ“‹ íŠ¹ì„± ëª©ë¡: {available_features}")
        
        # ë°ì´í„° ì •ê·œí™”
        X_scaled = self.scaler.transform(X_selected)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        result1 = self.model1.predict(X_scaled)  # ì—…ì²´íˆ¬ì°°ë¥ 
        result2 = self.model2.predict(X_scaled)  # ì˜ˆê°€íˆ¬ì°°ë¥ 
        result3 = self.model3.predict(X_scaled)  # ì°¸ì—¬ì—…ì²´ìˆ˜
        
        print("âœ… ì˜ˆì¸¡ ì™„ë£Œ")
        
        # ì„±ëŠ¥ í‰ê°€
        print("\nğŸ“Š ì„±ëŠ¥ í‰ê°€:")
        print("="*60)
        
        # ì—…ì²´íˆ¬ì°°ë¥  ì„±ëŠ¥
        y1_actual = dataset_y['ì—…ì²´íˆ¬ì°°ë¥ '].values
        mse1 = mean_squared_error(y1_actual, result1)
        r2_1 = r2_score(y1_actual, result1)
        mae1 = mean_absolute_error(y1_actual, result1)
        rmse1 = np.sqrt(mse1)
        
        print(f"ì—…ì²´íˆ¬ì°°ë¥  ëª¨ë¸:")
        print(f"  RÂ²:   {r2_1:.6f}")
        print(f"  RMSE: {rmse1:.6f}")
        print(f"  MAE:  {mae1:.6f}")
        
        # ì˜ˆê°€íˆ¬ì°°ë¥  ì„±ëŠ¥
        y2_actual = dataset_y['ì˜ˆê°€íˆ¬ì°°ë¥ '].values
        mse2 = mean_squared_error(y2_actual, result2)
        r2_2 = r2_score(y2_actual, result2)
        mae2 = mean_absolute_error(y2_actual, result2)
        rmse2 = np.sqrt(mse2)
        
        print(f"\nì˜ˆê°€íˆ¬ì°°ë¥  ëª¨ë¸:")
        print(f"  RÂ²:   {r2_2:.6f}")
        print(f"  RMSE: {rmse2:.6f}")
        print(f"  MAE:  {mae2:.6f}")
        
        # ì°¸ì—¬ì—…ì²´ìˆ˜ ì„±ëŠ¥
        y3_actual = dataset_y['ì°¸ì—¬ì—…ì²´ìˆ˜'].values
        mse3 = mean_squared_error(y3_actual, result3)
        r2_3 = r2_score(y3_actual, result3)
        mae3 = mean_absolute_error(y3_actual, result3)
        rmse3 = np.sqrt(mse3)
        
        print(f"\nì°¸ì—¬ì—…ì²´ìˆ˜ ëª¨ë¸:")
        print(f"  RÂ²:   {r2_3:.6f}")
        print(f"  RMSE: {rmse3:.6f}")
        print(f"  MAE:  {mae3:.6f}")
        
        # í‰ê·  ì„±ëŠ¥
        avg_r2 = (r2_1 + r2_2 + r2_3) / 3
        avg_rmse = (rmse1 + rmse2 + rmse3) / 3
        
        print(f"\ní‰ê·  ì„±ëŠ¥:")
        print(f"  í‰ê·  RÂ²:   {avg_r2:.6f}")
        print(f"  í‰ê·  RMSE: {avg_rmse:.6f}")
        
        return result1, result2, result3

    def save_result_to_excel(self, df_result, filename):
        """ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
        print(f"ğŸ’¾ ì—‘ì…€ íŒŒì¼ ì €ì¥ ì¤‘: {filename}")
        
        try:
            df_result.to_excel(
                filename,
                sheet_name='Sheet1',
                na_rep='NaN',
                float_format="%.8f",
                header=True,
                index=True,
                index_label="id",
                startrow=1,
                startcol=1,
                freeze_panes=(2, 0)
            )
            
            # í†µê³„ ì¶”ê°€
            self.add_result_statistics(filename, df_result)
            
            print(f"âœ… ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
            
        except Exception as e:
            print(f"âŒ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")
            # CSVë¡œ ëŒ€ì²´ ì €ì¥
            csv_filename = filename.replace('.xlsx', '.csv')
            df_result.to_csv(csv_filename, 
                           na_rep='NaN', 
                           float_format="%.8f", 
                           header=True, 
                           index=True, 
                           index_label="id",
                           encoding='utf-8-sig')
            print(f"âœ… CSV íŒŒì¼ë¡œ ì €ì¥: {csv_filename}")

    def add_result_statistics(self, filename, df_result):
        """ì—‘ì…€ íŒŒì¼ì— í†µê³„ ì¶”ê°€"""
        try:
            if not OPENPYXL_AVAILABLE:
                return
                
            wb = load_workbook(filename)
            ws = wb.active
            
            data_rows = len(df_result)
            start_row = 3
            end_row = start_row + data_rows - 1
            
            # ê²°ê³¼1 í†µê³„
            stats_row = end_row + 2
            ws[f'AC{stats_row}'] = "=== ê²°ê³¼1 í†µê³„ ==="
            ws[f'AC{stats_row}'].font = openpyxl.styles.Font(bold=True, color="0000FF")
            
            ws[f'AC{stats_row + 1}'] = "ë‚™ì°° ê°œìˆ˜:"
            count_formula1 = f'=COUNTIF(AD{start_row}:AD{end_row},"ë‚™ì°°")'
            ws[f'AD{stats_row + 1}'] = count_formula1
            
            ws[f'AC{stats_row + 2}'] = "ë‚™ì°° ë¹„ìœ¨:"
            rate_formula1 = f'=IF(AD{stats_row + 1}>0,AD{stats_row + 1}/{data_rows}*100,0)'
            ws[f'AD{stats_row + 2}'] = rate_formula1
            
            # ê²°ê³¼2 í†µê³„
            ws[f'AF{stats_row}'] = "=== ê²°ê³¼2 í†µê³„ ==="
            ws[f'AF{stats_row}'].font = openpyxl.styles.Font(bold=True, color="00AA00")
            
            ws[f'AF{stats_row + 1}'] = "ë‚™ì°° ê°œìˆ˜:"
            count_formula2 = f'=COUNTIF(AG{start_row}:AG{end_row},"ë‚™ì°°")'
            ws[f'AG{stats_row + 1}'] = count_formula2
            
            ws[f'AF{stats_row + 2}'] = "ë‚™ì°° ë¹„ìœ¨:"
            rate_formula2 = f'=IF(AG{stats_row + 1}>0,AG{stats_row + 1}/{data_rows}*100,0)'
            ws[f'AG{stats_row + 2}'] = rate_formula2
            
            wb.save(filename)
            print("ğŸ“Š í†µê³„ ì¶”ê°€ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ í†µê³„ ì¶”ê°€ ì‹¤íŒ¨: {e}")

    def test_model(self, test_filename):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ ê°œì„ ëœ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*80)
        
        # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        dataset_x, dataset_y, original_data = self.load_test_data(test_filename)
        
        # 2. ì˜ˆì¸¡ ìˆ˜í–‰ ë° ì„±ëŠ¥ í‰ê°€
        result1, result2, result3 = self.predict_and_evaluate(dataset_x, dataset_y)
        
        # 3. ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        print("\nğŸ“Š ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„± ì¤‘...")
        df_result = self.make_result_dataframe(dataset_x, result1, result2, result3, original_data)
        
        # 4. ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
        from datetime import datetime
        timestamp = datetime.now().strftime("%y%m%d%H%M")
        excel_filename = f"res/improved_model_test_result_{timestamp}.xlsx"
        self.save_result_to_excel(df_result, excel_filename)
        
        print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {excel_filename}")
        print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {len(df_result)}í–‰ x {len(df_result.columns)}ì—´")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ” ê°œì„ ëœ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # í…ŒìŠ¤í„° ì´ˆê¸°í™”
    tester = ImprovedModelTester()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì›ë³¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸)
    tester.test_model('bid_250921_1.csv')

if __name__ == "__main__":
    main()
