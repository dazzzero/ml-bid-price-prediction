# -*- coding: utf-8 -*-
"""
ê°„ë‹¨í•œ ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
í•„ìˆ˜ íŒ¨í‚¤ì§€ë§Œ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ìƒíƒœ ë¶„ì„

@author: user
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

def analyze_data_simple():
    """ê°„ë‹¨í•œ ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
    print("ğŸ” ê°„ë‹¨í•œ ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì‹œì‘...")
    
    # ë°ì´í„° íŒŒì¼ ë¡œë“œ
    data_file = 'data/sample_prediction_data.csv'
    print(f"ğŸ“ ë°ì´í„° íŒŒì¼ ë¡œë“œ: {data_file}")
    
    try:
        # CSV íŒŒì¼ ì½ê¸°
        data = pd.read_csv(data_file, encoding='utf-8', header=0)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {data.shape[0]}í–‰, {data.shape[1]}ì—´")
        
        # ê¸°ë³¸ ì •ë³´
        print(f"\nğŸ“Š ê¸°ë³¸ ì •ë³´:")
        print(f"  - ì´ í–‰ ìˆ˜: {len(data):,}")
        print(f"  - ì´ ì—´ ìˆ˜: {len(data.columns)}")
        print(f"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # ì»¬ëŸ¼ ì •ë³´
        print(f"\nğŸ“‹ ì»¬ëŸ¼ ëª©ë¡:")
        for i, col in enumerate(data.columns, 1):
            print(f"  {i:2d}. {col}")
        
        # ë°ì´í„° íƒ€ì…
        print(f"\nğŸ”¢ ë°ì´í„° íƒ€ì…:")
        dtype_counts = data.dtypes.value_counts()
        for dtype, count in dtype_counts.items():
            print(f"  - {dtype}: {count}ê°œ")
        
        # ê²°ì¸¡ê°’ ë¶„ì„
        print(f"\nâŒ ê²°ì¸¡ê°’ ë¶„ì„:")
        missing_data = data.isnull().sum()
        total_missing = missing_data.sum()
        print(f"  - ì´ ê²°ì¸¡ê°’: {total_missing:,}ê°œ")
        print(f"  - ê²°ì¸¡ê°’ ë¹„ìœ¨: {total_missing / (len(data) * len(data.columns)) * 100:.2f}%")
        
        if total_missing > 0:
            print(f"  - ê²°ì¸¡ê°’ì´ ìˆëŠ” ì»¬ëŸ¼ë“¤:")
            for col, count in missing_data[missing_data > 0].items():
                print(f"    * {col}: {count}ê°œ ({count/len(data)*100:.2f}%)")
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ í†µê³„
        numeric_cols = data.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            print(f"\nğŸ“ˆ ìˆ«ìí˜• ì»¬ëŸ¼ ê¸°ë³¸ í†µê³„:")
            stats_df = data[numeric_cols].describe()
            print(stats_df.round(4))
        
        # ì´ìƒì¹˜ ë¶„ì„ (ê°„ë‹¨í•œ ë°©ë²•)
        print(f"\nğŸš¨ ì´ìƒì¹˜ ë¶„ì„ (Z-score > 3):")
        outlier_summary = {}
        for col in numeric_cols:
            if col in data.columns and data[col].notna().sum() > 0:
                # Z-score ê³„ì‚°
                z_scores = np.abs((data[col] - data[col].mean()) / data[col].std())
                outliers = z_scores > 3
                outlier_count = outliers.sum()
                outlier_percentage = (outlier_count / data[col].notna().sum()) * 100
                outlier_summary[col] = {'count': outlier_count, 'percentage': outlier_percentage}
                
                if outlier_count > 0:
                    print(f"  - {col}: {outlier_count}ê°œ ({outlier_percentage:.2f}%)")
        
        # íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ì„
        target_cols = ['ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜']
        print(f"\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ì„:")
        for col in target_cols:
            if col in data.columns:
                print(f"  - {col}:")
                print(f"    * í‰ê· : {data[col].mean():.4f}")
                print(f"    * ì¤‘ì•™ê°’: {data[col].median():.4f}")
                print(f"    * í‘œì¤€í¸ì°¨: {data[col].std():.4f}")
                print(f"    * ìµœì†Ÿê°’: {data[col].min():.4f}")
                print(f"    * ìµœëŒ“ê°’: {data[col].max():.4f}")
                print(f"    * ê²°ì¸¡ê°’: {data[col].isnull().sum()}ê°œ")
                
                # ë²”ìœ„ ê²€ì¦
                if col in ['ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ']:
                    invalid_range = ((data[col] < 0) | (data[col] > 1)).sum()
                    if invalid_range > 0:
                        print(f"    * âš ï¸ ë²”ìœ„ ì´ˆê³¼ (0-1): {invalid_range}ê°œ")
        
        # ë°ì´í„° í’ˆì§ˆ ê°œì„  ì œì•ˆ
        print(f"\nğŸ’¡ ë°ì´í„° í’ˆì§ˆ ê°œì„  ì œì•ˆ:")
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬ ì œì•ˆ
        if total_missing > 0:
            print(f"\n1ï¸âƒ£ ê²°ì¸¡ê°’ ì²˜ë¦¬:")
            print(f"   - {total_missing}ê°œì˜ ê²°ì¸¡ê°’ ë°œê²¬")
            print(f"   - ê¶Œì¥: í‰ê· ê°’ ë˜ëŠ” ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´")
        
        # ì´ìƒì¹˜ ì²˜ë¦¬ ì œì•ˆ
        total_outliers = sum([info['count'] for info in outlier_summary.values()])
        if total_outliers > 0:
            print(f"\n2ï¸âƒ£ ì´ìƒì¹˜ ì²˜ë¦¬:")
            print(f"   - {total_outliers}ê°œì˜ ì´ìƒì¹˜ ë°œê²¬")
            print(f"   - ê¶Œì¥: IQR ë°©ë²•ìœ¼ë¡œ ì œí•œ ë˜ëŠ” ì œê±°")
        
        # ë°ì´í„° ì •ê·œí™” ì œì•ˆ
        print(f"\n3ï¸âƒ£ ë°ì´í„° ì •ê·œí™”:")
        print(f"   - ê¶Œì¥: StandardScaler ë˜ëŠ” RobustScaler ì‚¬ìš©")
        print(f"   - ì´ìœ : ì„œë¡œ ë‹¤ë¥¸ ìŠ¤ì¼€ì¼ì˜ ë³€ìˆ˜ë“¤ì„ ë™ì¼í•œ ë²”ìœ„ë¡œ ì¡°ì •")
        
        # íŠ¹ì„± ì„ íƒ ì œì•ˆ
        print(f"\n4ï¸âƒ£ íŠ¹ì„± ì„ íƒ:")
        print(f"   - ìƒê´€ê´€ê³„ê°€ ë†’ì€ íŠ¹ì„±ë“¤ ì œê±°")
        print(f"   - ì¤‘ìš”ë„ê°€ ë‚®ì€ íŠ¹ì„±ë“¤ ì œê±°")
        print(f"   - ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ íŠ¹ì„± ìƒì„±")
        
        return data, outlier_summary
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None, None

def suggest_quick_improvements(data):
    """ë¹ ë¥¸ ë°ì´í„° ê°œì„  ë°©ì•ˆ ì œì‹œ"""
    print(f"\nğŸš€ ë¹ ë¥¸ ë°ì´í„° ê°œì„  ë°©ì•ˆ:")
    
    # 1. ê²°ì¸¡ê°’ì„ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´
    print(f"\n1ï¸âƒ£ ê²°ì¸¡ê°’ ì²˜ë¦¬ (í‰ê· ê°’ ëŒ€ì²´):")
    numeric_cols = data.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if data[col].isnull().sum() > 0:
            mean_val = data[col].mean()
            data[col].fillna(mean_val, inplace=True)
            print(f"   - {col}: {data[col].isnull().sum()}ê°œ â†’ 0ê°œ")
    
    # 2. ì´ìƒì¹˜ ì œí•œ (IQR ë°©ë²•)
    print(f"\n2ï¸âƒ£ ì´ìƒì¹˜ ì œí•œ (IQR ë°©ë²•):")
    for col in numeric_cols:
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # ì´ìƒì¹˜ ê°œìˆ˜ ê³„ì‚°
        outliers_before = ((data[col] < lower_bound) | (data[col] > upper_bound)).sum()
        
        # ì´ìƒì¹˜ ì œí•œ
        data[col] = data[col].clip(lower=lower_bound, upper=upper_bound)
        
        if outliers_before > 0:
            print(f"   - {col}: {outliers_before}ê°œ ì´ìƒì¹˜ ì œí•œ")
    
    # 3. íƒ€ê²Ÿ ë³€ìˆ˜ ë²”ìœ„ ì •ì œ
    print(f"\n3ï¸âƒ£ íƒ€ê²Ÿ ë³€ìˆ˜ ë²”ìœ„ ì •ì œ:")
    target_cols = ['ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ', 'ì°¸ì—¬ì—…ì²´ìˆ˜']
    for col in target_cols:
        if col in data.columns:
            if col in ['ì—…ì²´íˆ¬ì°°ë¥ ', 'ì˜ˆê°€íˆ¬ì°°ë¥ ']:
                data[col] = data[col].clip(lower=0, upper=1)
                print(f"   - {col}: 0-1 ë²”ìœ„ë¡œ ì œí•œ")
            elif col == 'ì°¸ì—¬ì—…ì²´ìˆ˜':
                data[col] = data[col].clip(lower=1)
                print(f"   - {col}: 1 ì´ìƒìœ¼ë¡œ ì œí•œ")
    
    return data

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ê°„ë‹¨í•œ ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì‹œì‘")
    print("=" * 50)
    
    # ë°ì´í„° ë¶„ì„
    data, outlier_summary = analyze_data_simple()
    
    if data is not None:
        print(f"\n" + "=" * 50)
        print(f"ğŸ”§ ë¹ ë¥¸ ê°œì„  ì ìš©")
        print(f"=" * 50)
        
        # ë¹ ë¥¸ ê°œì„  ì ìš©
        improved_data = suggest_quick_improvements(data.copy())
        
        # ê°œì„ ëœ ë°ì´í„° ì €ì¥
        output_file = 'data/bid_result_quick_improved.csv'
        improved_data.to_csv(output_file, index=False, encoding='utf-8')
        print(f"\nğŸ’¾ ê°œì„ ëœ ë°ì´í„° ì €ì¥: {output_file}")
        
        print(f"\nâœ… ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ë° ê°œì„  ì™„ë£Œ!")
        print(f"ë‹¤ìŒ ë‹¨ê³„: ê°œì„ ëœ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ")
    else:
        print(f"âŒ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨")

if __name__ == "__main__":
    main()
